URL: https://www.scientificamerican.com/article/neuroscientists-should-set-a-high-bar-for-evidence-against-free-will/
TITLE: Neuroscientists Should Set a High Bar for Evidence against Free Will
DATE: March 4, 20255 min read
CONTENT:
Opinion March 4, 2025 5 min read Neuroscientists Should Set a High Bar for Evidence against Free Will Neuroscience research claiming to question the existence of free will may have been misinterpreted By Aaron Schurger, Adina Roskies & Uri Maoz edited by Dan Vergano Jorg Greuel/Getty Images Do you believe in free will? Some scholars do not—and they rely on evidence from the brain sciences to make their case. Some people find the dismissal of the idea that we are in control of our decisions and actions to be deeply disturbing. We, as professionals active in the field, know they do because we regularly receive their e-mails asking—often in desperation—about neuroscientific studies that seem to threaten the possibility of free will. Most of these assertions rest on scientists claiming to anticipate or predict choices based on brain activity observed before a person in an experiment is even aware of what their own choice will be. Free will naysayers contend that unconscious brain processes may initiate an action that a person then erroneously believes to be set in motion by their own volition. But what if the results of that research were misconstrued, with the devil lurking in the fine details that most people do not read or do not understand? Neuroscience research going back to the early 1980s claimed to demonstrate that conscious free will is an illusion (“conscious free will”refers to our conscious decisions determining our actions). These results accumulated like nails in the coffin of free will, offered up by neuroscientists and hammered in by the mainstream media, until, in 2016, the Atlantic declared, “There’s no such thing as free will.” If you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today. Not so fast. More recent studies, combining empirical data and computational modeling, suggest this prior research had been misinterpreted, and none of it bears on conscious free will one way or another. Neuroscience, we conclude, has not disproven conscious free will. Many cognitive neuroscientists in the field, including former “no-free-will” proponents, now acknowledge that the supposed neuroscientific evidence against it is dubious. Unfortunately, the public still hasn’t heard the news, and the idea that neuroscience has disproven conscious free will, or even free will in general, still hangs in the air. Once the sole purview of philosophers, free will and consciousness have been increasingly studied by neuroscientists. These topics differ from other areas of study in neuroscience in that they matter deeply to most, if not all, of humanity. In contrast, few would lose sleep over the relative importance of other human attributes, such as whether people can directly sense magnetic fields (magnetoreception). Science often moves forward by posing hypotheses that are later modified or rejected. Given the deep existential nature of research on volition, however, we face two very important questions: Where should we set the bar for evidence claiming to bear on free will? And how should we evaluate and interpret such evidence to know if or when it has been met? Recognizing what philosophers of science call “inductive risk,” or the costs of potential errors, we should set the bar high. The cost of mistakenly denying free will is considerable, as those troubled letters we received show. And there is good reason to doubt the evidence often cited. The neuroscience of volition typically focuses on immediate (or proximal) and meaningless decisions, (like “press the button from time to time, whenever you feel like it, for no reason at all”). The decisions we care about with respect to free will and responsibility, however, are ones that are meaningful and often have longer time horizons. Perhaps many, or even most, of our day-to-day decisions—choosing when to take the next sip from your water cup or which foot to put forward—are not acts of conscious free will. But maybe some decisions are. Fortunately, or unfortunately, those consequential ones are the most difficult ones to study. What would it take for neuroscience to disprove conscious free will? The evidence must clearly show that people settle on a decision unawares. Here the devil is indeed in the details of predicting behavior and inferring consciousness from brain activity. For example, using machine learning to “predict” behavior in advance of the conscious decision will not necessarily tell us much. Consider a simple free choice of pressing a button with your right hand or your left hand, where predictions that are about 60 percent correct might be statistically significant (compared with a coin toss of roughly 50 percent); such predictive power would not undermine conscious free will. Why not? Because a 60 percent accurate prediction might just pick up on a tendency toward one alternative or the other rather than a firm decision. Moreover, many of us have enduring preferences and character traits that affect some decisions, and it would be surprising if such choices were not at least somewhat predictable in advance based on brain activity. In addition, because consciousness and decision-making play out over time and rely on past experiences, prediction need not indicate determination. Thus, in such cases, the details of performance of the machine-learning classifier do matter, not just whether it is “significantly above chance.” In fact, anything less than close-to-perfect predictive accuracy may be equivocal. In addition, neuroscience results depend on their data-analysis method, which can mislead. For example, some digital data filters can, in effect, “leak” future information into the past, and analyses involving a sliding window can inadvertently allow the system’s data analysis to “peek” into the very future that it is trying to predict. The devil, again, is in the details. These considerations matter because new scientific data on free will are on the horizon, mainly because of the proliferation of invasive recordings from surgically implanted brain electrodes in humans. An informed reader needs to know what evidence would truly falsify conscious free will and what would not. To be clear, we are not arguing for or against the existence of conscious free will; we are talking about the data here and the way to know whether those data constitute evidence that undermines conscious free will. We must ensure that the paradigms that we investigate in neuroscience allow us to draw conclusions about the actions that pertain to conscious free will. For many behaviors, being predictable to some degree should not surprise us: Does it undermine your free will if we predict that you will brush your teeth before going to bed tonight? The neuroscientist Robert Sapolsky has taken a different approach. He discounts the brain data and instead focuses on statistical regularities—for example, that early-childhood adversity can negatively impact the kind of choices we make and outcomes we experience later in life. He argues in his book Determined that we are part of a deterministic world over which we have no influence and that statistics like the childhood adversity findings bear this out. We do not deny the reality of regularities; our actions today may indeed be constrained (or partly determined) by our past environment or experiences. But just how much constraint is enough to rob us of free will? The lack of very high predictability in those statistics leaves plenty of room for acts of conscious free will (again, it would be strange if your early life experiences had no effect whatsoever on your later life). Finally, we note that a single human brain is arguably far more complex than the entire Earth’s atmosphere, and we can’t even predict the weather more than a few days into the future. So throwing sophisticated AI at brain data is unlikely to enable us to predict future brain states based on past ones, at least any time soon. We leave open the possibility that we will get there one day (though you are free to disagree). But one thing is clear: we are not there yet. This is an opinion and analysis article, and the views expressed by the authors are not necessarily those of Scientific American. Aaron Schurger is an assistant professor of cognitive and computational neuroscience at Chapman University, with faculty appointments in the psychology department and the Brain Institute. Adina L. Roskies is a professor of philosophy at the University of California, Santa Barbara, and chair of the university’s cognitive science graduate emphasis. She is co-editor of A Primer on Criminal Law and Neuroscience. Uri Maoz is an associate professor of cognitive and computational neuroscience at Chapman University, with faculty appointments in the psychology department and the Brain Institute, as well as visiting appointments at the University of California, Los Angeles, and the California Institute of Technology.
--------------------------------------------------------------------------------
URL: https://www.scientificamerican.com/article/exoplanet-census-identifies-missing-planets-gap/
TITLE: Where Are the Universe’s Missing Planets?
DATE: March 2025
CONTENT:
February 18, 2025 12 min read Where Are the Universe’s Missing Planets? Planet demographics reveal a puzzling lack of worlds in a certain size range throughout the galaxy By Dakotah Tyler edited by Clara Moskowitz Ron Miller For centuries our solar system was the only planetary system known to humans. We had no proof other worlds existed beyond those in our own cosmic backyard, and we imagined that if other planetary systems were out there, they would mirror ours: small, rocky worlds orbiting close to their stars, with giant planets similar to Jupiter and Saturn farther out. Scientists studied the history of our sun and its satellites with all the tools they had, and they used the knowledge they gained to shape our understanding of how planets form and evolve. But about three decades ago astronomers discovered exoplanets circling stars that were not our own. In the years since, we have found thousands of them, shattering what we thought we knew about planets. It turns out that planetary systems in our galaxy exhibit remarkable diversity—some have tightly packed planets in exotic configurations; others are dominated by gas giants skimming their stars. Now a new era of planetary science has emerged: exoplanet demographics. By analyzing patterns in the sizes, orbits and compositions of the planets they detect, scientists are uncovering the real processes that shape planetary systems. What we are finding is not a simple narrative but a puzzle: striking trends in planet populations that challenge our understanding of how planets are born and grow. These trends offer new clues about the answers to fundamental questions: Why are there very few planets in particular size ranges—most notably a swath of “missing planets” somewhat larger than Earth? Why does our solar system lack the most common types of planets in the galaxy—those larger than Earth but smaller than Neptune? And perhaps most important, how do these findings affect our search for habitable worlds? If you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today. Unraveling these mysteries isn’t just about studying individual planets—it’s about seeing the big picture. By investigating the patterns in exoplanet demographics, we’re learning not only what makes planetary systems tick but also where our solar system fits into this galactic context. Ultimately, we want to know whether our planet is rare—or whether the conditions that allowed life to arise here might be plentiful out there. The first confirmed exoplanets were discovered in 1992 orbiting a pulsar—a radio-wave-emitting, rapidly rotating neutron star formed from the aftermath of a massive star turned supernova. It’s still unclear whether these pulsar planets survived the supernova explosion or formed from its debris. In either case, they are outliers in the known exoplanet dataset. The real breakthrough came in 1995 with the discovery of 51 Pegasi b, the first exoplanet found orbiting a sun-like star. This world defied all expectations. Rather than a distant gas giant like Jupiter, 51 Pegasi b was a behemoth half the mass of Jupiter but orbiting astonishingly close to its star, whipping around it once every 4.2 days. At such proximity the planet would broil at around 1,800 degrees Fahrenheit, hot enough to vaporize some metals. Although 51 Pegasi b has only about half Jupiter’s mass, this extreme temperature causes the gas to inflate, giving the planet a radius twice as big as Jupiter’s. Astronomers dubbed this strange new class of planets “hot Jupiters.” The existence of hot Jupiters threw a wrench into the leading planet-formation models. Theories had been based on the structure of our solar system, where rocky worlds orbit close to the sun, and gas giants stay much farther out in colder regions where they can accumulate hydrogen and helium gas. But here was a Jupiter-mass world that somehow occupied the searing-hot inner reaches of its planetary system. If massive planets could form so close to their stars—or form farther out and move there later—what other unexpected arrangements might exist? We want to know whether our planet is rare—or whether the conditions that allowed life to arise here might be plentiful. Astronomers discovered 51 Pegasi b by detecting a wobble in its star’s motion caused by the gravitational tug of the orbiting planet—a technique called the Doppler (or radial velocity) method. As a planet orbits, it pulls its star slightly toward it. From our perspective on Earth, that star moves closer toward and then away from us (if the orbit is at the right angle from our line of sight), causing the star’s light to alternately redshift and blueshift, similar to the way the pitch of an ambulance siren rises as it approaches and falls as it passes by. The more massive the planet and the closer its orbit, the greater the stellar wobble and the easier it is to detect. That’s why the first exoplanets found with this method were hot Jupiters—and why this strategy has a strong detection bias for large planets in close orbits. As more planets were discovered with the radial velocity method, patterns began to emerge. By 2008, after surveying hundreds of stars, researchers found that about 10 percent of sun-like stars host giant planets within a few times the Earth-sun distance (called an astronomical unit). Yet these early demographic patterns were clouded by our observation biases. A major step forward in planetary demographics came when NASA launched its Kepler Space Telescope. By staring continuously at more than 150,000 stars for four years, Kepler detected thousands of planets, using what’s called the transit method. It searched for the slight dimming of a star’s light that occurs when a planet passes in front of it from our point of view. The results were startling: Erik A. Petigura, my Ph.D. adviser at the University of California, Los Angeles, analyzed the Kepler data and showed that approximately half of all sun-like stars host at least one planet between Earth and Neptune in size. These planets, which don’t exist in our solar system at all, seem to make complete orbits around their stars in weeks or months rather than years. In retrospect, it had been shortsighted to think our solar system was the galactic template. As a rule of thumb in astronomy, however, it’s usually safe to assume our perspective is average and not special, so I think we can be forgiven. As the Kepler sample grew, a mystery became more and more apparent. Astronomers saw a striking dearth of planets with sizes around 1.6 to 1.9 Earth radii, which they called the radius gap. This finding was no detection-bias fluke—after researchers had accounted for all the selection effects and biases in the observations, the gap remained. Something about planet formation or evolution must actively prevent planets from maintaining this intermediate size, most likely a process that strips atmospheres from planets in this range. Adding further intrigue to this puzzle is a phenomenon known as the “hot Neptune desert.” Planets the size of Neptune are conspicuously absent on orbits shorter than about three days. The reasons for this scarcity are still under investigation, but extreme radiation from stars at this distance and tidal forces probably contribute to this trend. Just as we see with smaller planets that have masses near the radius gap, short-period Neptunes are especially vulnerable to atmospheric loss. Over time their thick gaseous envelopes may be completely stripped away, leaving behind bare, rocky cores that we might classify as super Earths—scaled-up versions of our rocky world. Scientists think the hot Neptune desert is therefore a more extreme case of the same processes shaping the radius gap. (As we gathered more observations, some theories even predicted these features as a consequence of the radiation streaming from stars.) Nadieh Bremer; Source: “The California-Kepler Survey. X. The Radius Gap as a Function of Stellar Mass, Metallicity, and Age,” by Erik A. Petigura et al. in Astronomical Journal, Vol. 163; March 2022 (data) Follow-up radial velocity observations with ground-based telescopes added another crucial piece to the puzzle. By measuring the masses of known exoplanets, astronomers found that the radius gap corresponds to a transition in composition. Planets with masses below the gap are dense and rocky like Earth, whereas those above it have lower densities, indicating substantial atmospheres. The smaller planets appear to be super Earths. The larger ones are “mini Neptunes” with rocky cores enshrouded by thick layers of hydrogen and helium. This demographic pattern poses fundamental questions. Do all small planets start with substantial atmospheres, and do some lose them over time? Or do they form with different compositions from the beginning? Recent observations of planets actively losing their atmospheres suggest gas loss plays a significant role. Astronomers think there are several processes that can rip atmospheres off planets or limit their formation in the first place. The two leading contenders are photoevaporation and core-powered mass loss. Together they may explain the radius gap and the hot Neptune desert. Photoevaporation is one of the best explanations for the radius gap. When young stars ignite, they unleash extreme ultraviolet and x-ray radiation, along with powerful winds of charged particles. Planets that orbit too close to their host stars find themselves bathed in this radiation, which heats their atmospheres to the point where particles can escape into space. Imagine two newly formed planets orbiting at the same distance from their respective stars, each starting with a rocky core and a substantial hydrogen-helium gas envelope. Planet A has a lower mass and weaker gravity, so it can’t hold on to its atmosphere as the star pumps energy into it. It quickly loses all its gas to space and becomes a dense, rocky super Earth. When we observe this system, the atmosphereless planet appears smaller in size. Planet B, however, has a higher mass and stronger gravity, which allows it to retain most of its atmospheric envelope. When we observe this system, the planet appears large because of its light and puffy primordial cocoon. The photoevaporation theory makes several predictions that match observed patterns. For example, the radius gap should slope downward with orbital period because planets closer to stars experience more intense radiation and need to be more massive to survive with their atmospheres intact. Similarly, we see a lack of Neptune-size planets with orbits shorter than three days, the so-called hot Neptune desert. This region is where atmospheric escape is so efficient that only rocky cores can survive. The second mechanism for the disappearance of planet atmospheres is core-powered mass loss, which is caused by the heat generated within a planet. After planets form, they hold on to significant amounts of heat from the process of pulling mass into themselves. This residual internal energy can warm the base of the atmosphere as the planet cools, lifting up the primordial envelope from below and helping gas to escape, along with the pull from stellar radiation. Our solar system, once thought to be the blueprint for all planetary systems, now stands as just one of countless possibilities. Core-powered mass loss suggests that smaller and less massive planets, with weaker gravity and less insulating gas, lose their atmospheres from below as they cool over hundreds of millions of years. Larger planets, in contrast, have enough gravitational strength to retain their envelopes despite the internal heating. This mechanism also aligns with the radius gap, given that intermediate-size planets are most susceptible to atmospheric loss through this process. Ultimately, hot planets cool off, and stellar irradiation heats up atmospheres. Astronomers think both mechanisms are at work, but the jury is still out on which theory has its thumb pressed more heavily on the planetary-evolution scale. It’s likely the outcome depends on the specific conditions of the planet in question. Other processes may also contribute. The rapid boil-off theory, for instance, posits that during a planet’s early years, shortly after its star has formed, the debris disk circling the star—which contains the raw ingredients that were used to build the planets—gets cleared out. The resulting rapid drop in pressure around the planet may drive a sudden boil-off phase for its atmosphere. In other cases, planets may form in gas-poor environments. These worlds would naturally lack thick atmospheres from the start, leading to a rocky composition. Finally, massive impacts between young planets could strip away their atmospheres, leaving behind bare, rocky cores in what’s called collisional stripping. Although this process is probably rare, it may explain some planetary populations. Recent observations have begun to catch some of these situations in action, providing direct evidence of atmospheric escape. Because planets are most likely to let go of mass when they’re young, most small planets we can observe aren’t undergoing significant loss. There is, however, a favorable scenario for observing an atmosphere escaping in real time: a gas giant on a close-in orbit, also known as a hot Jupiter. A compelling example is the planet WASP-69b, which my group observed using the telescope at the W. M. Keck Observatory in Hawaii. WASP-69b is a Jupiter-size, Saturn-mass gas giant orbiting so close to its star that a full trip around it takes the planet only 3.8 days. In a paper we published in 2024, we reported outflows of material around the planet that indicate it is actively losing helium. In this case, the mass-loss mechanism must be photoevaporation. The planet is too massive to lose mass to internal heating; instead it’s getting blasted with high-energy radiation from its host star. Our observations revealed that WASP-69b is losing about 200,000 tons per second, or one Earth mass per billion years. Furthermore, there have been dramatic variations in the shape of the outflow of escaping gas: sometimes it has a cometlike tail stretching over 350,000 miles, and at other times it appears far less prominent. This variability in outflow probably stems from changes in the host star’s activity. Much as our sun cycles through periods of heightened and decreased activity during its magnetic cycle, stars can experience periods of more or less intense radiation and flaring. Stretches of heightened stellar activity might boost atmospheric escape rates and change the shape of any material rushing off the planet. This dynamic interplay between star and planet illustrates that atmospheric loss may not be a steady, uniform process even in more mature planets. Rather it’s an ongoing battle shaped by both the properties of the planet and the mood of its star. Our findings and others show how photoevaporation can help explain both the radius gap and the hot Neptune desert by demonstrating this mass-loss process in real time. For a given orbital distance, planets require a minimum mass to hold on to their atmospheres amid the onslaught of high-energy stellar radiation. The radius gap separates the planets that are massive enough from those that are not. The hot Neptune desert demonstrates how this concept is amplified as a planet gets nearer to the star and the stellar irradiation increases exponentially. At sufficient proximity to a star, only hot Jupiters have the mass required to retain an atmosphere—all other planets get stripped to their bare, rocky core. The next decade should be an exciting stage for refining our understanding of planetary demographics. Although most astronomers agree that atmospheric mass loss is the primary reason we don’t see slightly bigger Earths or hot Neptunes on close orbits, the finer details remain unresolved. Is photoevaporation, driven by stellar radiation, the dominant factor? Or does core-powered mass loss, fueled by a planet’s internal heat, play a larger role? Untangling the contributions of these mechanisms requires a new generation of telescopes and instruments capable of precisely measuring planetary masses, compositions and atmospheres. We hope to better understand how the radius gap depends on stellar type. For low-mass stars, such as M dwarfs, the radius gap appears to shift—smaller planets around these stars are able to retain atmospheres more often because they are exposed to less radiation than larger stars put out. The radius gap is usually less defined because low-mass stars put out different kinds of radiation than larger stars. The planets around these stars also tend to have greater core-composition diversity, and these systems may have an increased rate of major collisions. Planets around M dwarfs also tend to orbit much closer, where stellar activity such as flares and winds can have a big effect on atmospheric retention. Close inspection of these worlds has revealed hints that some of them might harbor significant amounts of water, potentially in the form of deep global oceans underneath hydrogen-rich atmospheres. These “water worlds” would occupy a unique position in planetary demographics, challenging simple models of rocky super Earths and gas-rich mini Neptunes. New ground-based instruments such as the Keck Planet Finder, which recently went online at the Keck observatory, and other high-precision radial velocity tools will be indispensable in testing our theories. By enabling us to measure planetary masses across a wide range of star types, these advances will help us determine whether the masses of super Earths and sub Neptunes align with predictions from our various models. In multiplanet systems, these kinds of data can help disentangle the effects of stellar irradiation history, allowing researchers to compare planets that formed under similar conditions. NASA’s Transiting Exoplanet Survey Satellite mission is conducting extended monitoring over long timescales that could reveal planets with slightly wider orbits around their stars than most known worlds have. By filling out this sparsely populated region of small exoplanets with longer orbital periods, these discoveries will provide crucial data for understanding how atmospheric loss and composition vary across a broader range of planetary environments. The big leap forward should come when some big-ticket telescopes come online in the next decades. Ground-based super telescopes, such as the European Southern Observatory’s Extremely Large Telescope, are expected to see first light in the late 2020s. These instruments will excel at observing young, luminous planets still glowing with the heat of their formation. Such gigantic telescopes will offer critical insights into the chaotic early stages of planetary evolution, when atmospheres are most vulnerable to loss. The Habitable Worlds Observatory, a NASA flagship space telescope, is planned to launch in the 2040s. It is being designed to detect and study Earth-like planets in the habitable zones of sun-like stars. The aim is to use the observatory to directly image these worlds and analyze their atmospheres to search for signs of oxygen, methane and water vapor—key indicators of habitability. What we learn from all these new tools will reach far beyond planetary demographics. By studying how planets lose or retain their atmospheres, we are unlocking the secrets of habitability, diversity and the forces that sculpt worlds across the galaxy. Our solar system, once thought to be the blueprint for all planetary systems, now stands as just one of countless possibilities—a unique configuration in a cosmos teeming with variety. Most stars host planets unlike anything in our cosmic neighborhood, reminding us that the universe is richer and more surprising than we have imagined. By untangling the forces that shape these distant worlds, we inch closer to answering some of humanity’s oldest questions: How common are planets like Earth? Is there other life among the stars? And what does our place in this vast and intricate universe truly mean? Life as We Don’t Know It. Sarah Scoles; February 2023. Scientific American.com/archive Dakotah Tyler is an astrophysics Ph.D. candidate at the University of California, Los Angeles. His research focuses on exoplanet atmospheres and how planets lose mass as they evolve.
--------------------------------------------------------------------------------
URL: https://www.scientificamerican.com/article/five-years-after-the-covid-pandemic-began-fatigue-and-frustration-remain/
TITLE: COVID Pandemic Fatigue Has Left the U.S. Vulnerable to New Threats
DATE: March 7, 20258 min read
CONTENT:
March 7, 2025 8 min read COVID Pandemic Fatigue Has Left the U.S. Vulnerable to New Threats The “quarantine fatigue” of 2020 became an ongoing “pandemic fatigue,” a complex set of emotions that continues to affect the nation By Meghan Bartels edited by Tanya Lewis People wearing protective masks wait on a subway platform at Grand Central in New York, U.S., on Monday, Sept. 21, 2020. Michael Nagle/Bloomberg via Getty Images During the five-plus years that COVID has existed, our conception of the virus that causes it has been a slippery thing. It has been a terrifying mystery and a daily reality, a killer pathogen and “just the flu,” an alphabet of variants that burst on the scene only to disappear from public consciousness. Amid all this morphing, what has stayed constant is that COVID has been, in one way or another, wearying in a bone-deep way. It was tiring to disinfect surfaces and then to learn that the virus was in fact airborne. It was tiring to scramble for toilet paper, for masks, for vaccines. It was tiring to fear an invisible virus and to stay away from other people. And it has been tiring to return to society—whether with abandon, fear or something in between. Regardless of how each of us has responded to the virus’s threats, its shadow has haunted our lives for five years in ways we never even thought to imagine before we encountered the then novel coronavirus SARS-CoV-2. “I think we’re all exhausted, and we’re not actually admitting it,” says Alexandre White, a sociologist and historian of medicine at Johns Hopkins University. That’s a problem, he says. “There’s real power in mourning and real power in memorial,” White says. “I think we’ve too easily moved on from COVID in such a way that we assume that since we all lived through it, there’s nothing really more to talk about, and I think that there’s a lot more to talk about.” If you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today. Discussing how each of us experienced the past five years and its many stressors—and listening to others do the same—could be a way to heal the rifts that COVID has left in U.S. society. Not long after COVID hit the U.S. in earnest, the phrase “quarantine fatigue” had come into use. As the days turned to months, the language morphed into “pandemic fatigue.” But the fatigue itself has had countless sources over the years, and the term has often encompassed many more emotions than simply fatigue, including loneliness, sadness, anger, fear and boredom. Each person’s experience was influenced by a host of factors. The most severe one, of course, has been death—so much death. In 2020 COVID killed or contributed to the deaths of at least 385,000 people in the U.S. And in 2021 the number was more than 463,000, according to the Centers for Disease Control and Prevention. Losing family members early, without proper deathbed visits or funerals, brought a particular type of pain. And while their rate has declined, the deaths have continued. As of March 6, the five-year death toll was 1,225,281 people. Even now, the tally grows by hundreds every week. Those of us who have so far escaped COVID without it stealing loved ones have nonetheless faced grief, stress and fear, particularly during the early weeks and months of the pandemic, that were unthinkable to many Americans in 2019. Medical professionals suffered high rates of burnout and moral injury. The people classified as essential workers—grocery cashiers and farm workers, delivery drivers and electricians—found themselves suddenly risking their lives for their jobs. Children abruptly had to learn from a screen, while working parents, particularly mothers, attempted to simultaneously oversee a makeshift classroom. Proms and holiday gatherings, happy hours and vacations were all canceled. In October 2024 half of U.S. adults surveyed about their experience said that COVID took a minor toll on their lives; another quarter say it took a major one. Thirty percent overall said they had experienced a toll that they had not or only somewhat recovered from. El Centro Fire Department firefighter/paramedic Chase Adame decontaminates his PPE (personal protective equipment) after treating a woman who fell in a parking lot in hard-hit Imperial County amid the COVID-19 pandemic on July 21, 2020, in El Centro, California. Mario Tama/Getty Images It’s not surprising that COVID’s acute stages took a toll in the U.S.—or that the recovery has been difficult here. The country was out of practice when it came to dealing with pandemics. Many of the disease scares of recent decades—SARS, MERS, Ebola, Zika—in large part spared the U.S. Even the swine flu of 2009, which killed 12,500 people in the country within its first year, fizzled out in less than two years. The spread of HIV/AIDS has been devastating, but its transmission routes have allowed many Americans to feel isolated from its threats. The previous most severe respiratory epidemic the U.S. faced was the influenza pandemic of 1918, a full century before COVID. The 1918 pandemic was very different from the rise of COVID in 2020, says Nancy Tomes, a historian at Stony Brook University. In the U.S. the bulk of influenza infections occurred during just a couple of months in the fall of 1918 and while the nation was at war. People were used to devastating infectious diseases in the early 20th century—still, the U.S. public struggled with pandemic restrictions. “Even at a time when the majority of Americans had experience with deadly infectious diseases and were much easier to scare, they had trouble changing their behavior to prevent the spread of something fast-moving,” she says. Since then scientists and doctors have had some success in taming germs, thanks to the twin wonders of vaccines and treatments, Tomes says. “Americans had started to expect that there’s a drug for everything and a vaccine for everything”—and that “if there is a dangerous new disease and there isn’t an immediate cure or vaccine for it, somebody has done something wrong,” she says. When COVID first hit, many people leaned into their communities, making sacrifices in attempts to protect neighbors and loved ones. But as time went on, communal thinking seemed to fray in the face of clear challenges. Solidarity disintegrated as a host of factors lumped into a diagnosis of “pandemic fatigue” took root. Scientists scrambled to understand COVID and the virus that caused it—with some remarkable success. But to everyday people living in fear, the process was a far cry from the grade-school vision of how settled science works. “This was a lot more uncertain,” says Richard Carpiano, a public health scientist and sociologist at the University of California, Riverside. “What the public really got out of this was a front-row seat to watching science unfold.” Early in the pandemic, some people who survived COVID didn’t fully recover. These “long haulers,” as they were soon dubbed, fought against medical systems that didn’t expect the new virus to trigger an array of disabling long-term conditions that came to be known as long COVID. Today people with this condition are learning how limited support for people with such disabilities can be in the U.S. “While a virus was invading people’s bodies, it also really crept into these fault lines of our society and our culture.” —Richard Carpiano, public health scientist and sociologist Unsurprisingly, COVID hit society’s least-privileged members hardest: people of color, low-income people and the elderly. “Inequality haunts every epidemic,” White says. “Epidemics can cause inequities in a society, but more often than not, they prey very effectively on the existing inequities within the population.” Pandemic action plans failed to account for opposition to safety measures, including school closures, mask mandates and vaccination, says Andrew Lakoff, a medical anthropologist at the University of Southern California. Political actors seized on this dissent to drive people apart. “We were suffering from anxiety and a lot of people getting sick and dying, and the social fabric was getting torn apart,” he says. Despite the virus’s novelty, scientists produced effective vaccines against it on a miraculously short time line, deploying them within a year after infections began. But existing antivaccine efforts that focused on childhood vaccines and targeted mainly parents also moved fast, latching on to the new vaccines. “The COVID vaccine that the whole population had to take diffused a lot of the antivaccine discourse into the general public,” Carpiano says. Throughout it all, medical professionals who had risked their lives from the beginning found themselves not only still facing a constant onslaught of patients but now also trying to squash misinformation and denial about the disease. As these threats built and COVID continued to bulldoze its way across the U.S, people moved away from collective care for one another’s health. COVID shots became an annual ritual for some, but only one in every four or five adults in the U.S. now gets the vaccine. Only 4 percent of U.S. adults report regularly wearing a mask, which reduces transmission of not only COVID but also colds, the flu and other respiratory infections. “COVID was a radical test of collective unity, and America deeply unveiled its individualism and lack of collective heart,” says Emily Mendenhall, a medical anthropologist at Georgetown University. Whatever the source of fatigue, the U.S. public generally was eager for the COVID pandemic to end. “Pandemics end when a sizable proportion of the population feels that they’re not at risk from the disease anymore,” White says. This occurs regardless of how accurate the assessment is or how poorly it applies to the rest of the population. “There’s a certain luxury in claiming a pandemic’s ending,” he says. In March 2025 it’s easy to feel the world is just as chaotic as it was five years ago—or worse. “I think people are sick of talking about COVID, and I don’t think it’s because people don't care,” Mendenhall says. “I think it’s just because there are so many more pressing issues right now.” The pandemic pushed U.S. society past its limits in ways that continue to reveal themselves. Donald Trump is president again, politics are more divisive than ever, and bird flu threatens to become the next human pandemic, even as the president is axing science and social safety nets. The timing may not be a coincidence, given how the pandemic made people reevaluate their relationship with the government and the role they want it to play in their lives. “While a virus was invading people’s bodies, it also really crept into these fault lines of our society and our culture,” Carpiano says. “It makes us think about our social contract with our government in terms of what it means to provide for our well-being and for our safety.” None of these trends bodes well for the U.S.’s ability to effectively respond to the next public health crisis—whether it’s avian influenza or something else. White sees a sharp contrast with the 1918 pandemic: by its end, no one wanted to talk about it, but its memory helped inspire the creation of the World Health Organization and other antipandemic measures. Today it’s primarily community organizers and long COVID activists, as well as public health experts, who are leading efforts to turn the painful experience of COVID into something that can help prepare us for future disease threats. “Pandemic preparedness is not a last-ditch solution; it’s really a constant set of strategies for monitoring such threats,” White says. “I’m concerned today with pandemic defeatism—where rather than maintain systems prepared for another pandemic or continue combating COVID-19, we might be too quickly choosing to ignore the very real risks that are out there and instead throw up our hands, suggesting that there’s perhaps nothing we can do.” In our exhaustion, that strategy may sound appealing. But it risks even more dire consequences than the ones COVID has brought. “That would be such an incomprehensible tragedy,” White says. “We can do better—and we have to do better, for each other.” Meghan Bartels is a science journalist based in New York City. She joined Scientific American in 2023 and is now a senior news reporter there. Previously, she spent more than four years as a writer and editor at Space.com, as well as nearly a year as a science reporter at Newsweek, where she focused on space and Earth science. Her writing has also appeared in Audubon, Nautilus, Astronomy and Smithsonian, among other publications. She attended Georgetown University and earned a master’s degree in journalism at New York University’s Science, Health and Environmental Reporting Program.
--------------------------------------------------------------------------------
URL: https://www.scientificamerican.com/issue/sa/2025/03-01/
TITLE: Scientific American Magazine
DATE: March 2025
CONTENT:
The Brain Science of Elusive ‘Aha! Moments’ What happens in your mind when insight strikes? John Kounios, Yvette Kounios
--------------------------------------------------------------------------------
URL: https://www.scientificamerican.com/article/the-surprisingly-difficult-mathematical-proof-that-anime-fans-helped-solve/
TITLE: How Anime Fans Stumbled upon a Mathematical Proof
DATE: March 3, 20256 min read
CONTENT:
March 3, 2025 6 min read How Anime Fans Stumbled upon a Mathematical Proof When a fan of a cult anime series wanted to watch its episodes in every possible order, they asked a question that had perplexed combinatorial mathematicians for years By Manon Bischoff edited by Daisy Yuhas Fans of a classic anime series sought to work out how long it would take to the watch a 14-episode series in every possible order as efficiently as possible. Yuriko Nakao/Getty Images Math solutions can be found in surprising places, including the dark realms of the Internet. In 2011 an anonymous poster on the now infamously controversial image board 4chan posed a mathematical puzzle about the cult classic anime series The Melancholy of Haruhi Suzumiya. Though the bulletin board has become littered with hateful, violent and extreme content, that original post led to a solution to the sophisticated math problem. The first season of this anime series consists of 14 episodes that were designed so that you can watch them in any order you like. (For people who are as unfamiliar with the anime world as I am: an eight-part live-action thriller called Kaleidoscope on Netflix follows the same principle.) At some point in a 2011 discussion of the series on 4chan, someone asked the minimum number of episodes they would have to watch to have seen it in every possible order. In fact, this question is related to so-called superpermutations. And as it turns out, this mathematical area holds many puzzles: to this day, mathematicians are still unable to fully answer the problem that the 4chan user had posed. If you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today. But amazingly, in that discussion, one of the anonymous users made an estimate of the minimum amount of all episodes to watch with an approach that was previously unknown to mathematicians. “I’ll need to [elaborate on] this in multiple posts. Please look it over for any loopholes I might have missed,” wrote the user, who explained in several steps how they arrived at their estimate. Other users then took up the arguments and discussed them—but outside of 4chan, none of this made any waves. No one seemed to take any notice. In mathematics, two objects permutate when they are rearranged or recombined. For example, you can permutate AB to BA. If an anime series consisted of only two parts, you could either watch the first and then the second episode (1-2) or the second and then the first (2-1). If you want to watch a series in multiple arrangements—perhaps to figure out which sequence of episodes makes the most sense—you need a superpermutation. This is a sequence of all possible permutations. Imagine a marathon showing where you watch the first episode, followed by the second, and then watch the second episode, followed by the first (1-2-2-1). To avoid watching the second episode twice in a row, a shorter superpermutation would be 1-2-1; you would only have to watch three episodes to still have every possible order covered. If a series consists of three episodes, it becomes a little trickier to find the shortest superpermutation. In this case, there are 3! = 6 different sequences: 1-2-3, 1-3-2, 2-3-1, 2-1-3, 3-1-2, 3-2-1. Fortunately, you don’t have to watch 3 × 6 = 18 parts but can find a clever shortcut, in this case: 1-2-3-1-2-1-3-2-1. That order contains all possible permutations of the numbers 1, 2 and 3, but you only have to watch nine episodes! Mathematicians have also calculated the shortest superpermutations for a series consisting of n = 4 and n = 5 episodes (33 and 153 episodes, respectively). Beyond that, however, they are in the dark. The shortest superpermutations for n > 5 are not known. In fact, the challenge relates to one of the most intractable problems in algorithmics: the traveling salesperson problem. In this problem, a person wants to visit different cities and end up back in their hometown. The task is to find the shortest route that connects all the cities. The shortest superpermutation is a variation of this problem in which the individual permutations represent different cities. In this case, you assign different distances between cities by determining the overlap of the permutations. For example, cities 1-2-3 and 2-3-1 have a large overlap: the last two digits of the first permutation match the first two digits of the second, so they can be combined to form 1-2-3-1. We can therefore assign a short distance between those two cities. On the other hand, 1-2-3 and 2-1-3 do not overlap. (To see both sequences, you have to look at a full six parts; no shortcut is possible.) Thus, these cities have a large distance between them. To find the shortest route within permutations, you connect the permutations that overlap the most. There is only one difficulty: there is no known algorithm that solves the traveling salesperson problem quickly. If we are dealing with a few cities—or, in the case of an anime series, a few episodes—this is not a major drawback. But as soon as the n becomes large, computers fail at the task because the computing time grows exponentially with n. Computers are able to calculate superpermutations for n = 4 and n = 5 but not for anything beyond that. And although it is possible to calculate elaborate superpermutations for larger numbers, finding the shortest superpermutation becomes more difficult. Experts must therefore make do with estimates. For example, there is an algorithm that helps estimate the length of the shortest possible superpermutation for n objects: 1! + 2! + 3! + ... + n! Using that algorithm, if n = 2, you get a superpermutation of length 1 + 2 = 3. For n = 3, this results in a length of 1 + 2 + 6 = 9. For n = 4, you get 33. And for n = 5, you get 153, which corresponds to the shortest superpermutation in each case. For larger n, however, this algorithm no longer applies: computers have been able to find shorter superpermutations than it would suggest exists. In fact, the formula 1! + 2! + 3! + ... + n! massively overestimates the length of the shortest superpermutation for large n. Although the algorithm offers only an approximate answer, mathematicians use it as a starting place, with the goal of narrowing down options to find more precise answers. In 2013 Nathaniel Johnston, now a mathematics professor at Mount Allison University in New Brunswick, landed on a Melancholy of Haruhi Suzumiya fandom page. Johnston himself was not an anime fan. He had arrived at the site after Googling some search terms related to superpermutations. There he came across the discussion that had been held on 4chan almost two years earlier, which a user had copied to the fandom site. Johnston didn’t bother doing the math but cited the fandom post on his blog. This comment, too, went unnoticed for several years. Then in October 2018 mathematician Robin Houston came across his colleague’s blog post through a curious coincidence. Houston had just learned that Australian science fiction author Greg Egan had found a new maximum length for the shortest superpermutations, expressed as: n! +(n –1)! + (n – 2)! + (n – 3)! + n – 3 That in itself was bizarre. But when Houston started learning more about this result, he realized that the minimum length of a superpermutation had been given a new value by an anonymous anime fandom user (he didn’t know about the origins on 4chan at that time). The formula for the minimum length is: n! +(n – 1)! + (n – 2)! + n – 3 Houston shared his discovery on Twitter (now X) on October 23 of that year. “A curious situation. The best known lower bound for the minimal length of superpermutations was proven by an anonymous user of a wiki mainly devoted to anime,” he wrote. Along with his colleagues, mathematicians Jay Pantone and Vince Vatter, Houston decided to check the 4chan user’s proof and write it down in a mathematical way. The researchers posted their mathematical work to the Online Encyclopedia of Integer Sequences that same month, and the first author is listed as “Anonymous 4chan Poster.” So what do these formulas tell us? If you want to watch all episodes of an n-part series in all possible combinations, you must sit through at least n! +(n – 1)! + (n – 2)! + n – 3 episodes—that’s the 4chan user’s contribution—and at most n! +(n – 1)! + (n – 2)! + (n – 3)! + n – 3, which we know through Egan’s work. In the case of the eight-episode series Kaleidoscope, you would have to watch at least 46,085 and, at most, 46,205 episodes. For The Melancholy of Haruhi Suzumiya, or Haruhi, with 14 episodes, the number increases drastically: a minimum of 93,884,313,611 episodes and a maximum of 93,924,230,411. Recall that this is not a complete solution—it’s just setting a range for the size of a superpermutation that would allow you to efficiently watch the series in every possible order. Fortunately, Egan also provided an algorithm for constructing the corresponding superpermutation. This allows Haruhi fans to work out the best viewing order of episodes. But with an average episode length of around 24 minutes, it would take about 4 million years to sit through this superpermutation. Manon Bischoff is a theoretical physicist and editor at Spektrum, a partner publication of Scientific American.
--------------------------------------------------------------------------------
URL: https://www.scientificamerican.com/article/trump-administration-likely-to-drop-chloroprene-lawsuit-heres-what-that/
TITLE: What Is Chloroprene, the Cancer-Causing Chemical at the Center of a Federal Lawsuit?
DATE: March 7, 20255 min read
CONTENT:
March 7, 2025 5 min read What Is Chloroprene, the Cancer-Causing Chemical at the Center of a Federal Lawsuit? Trump could drop a federal lawsuit against a petrochemical plant that emits chloroprene. Here’s a look at the cancer-causing chemical By Stephanie Pappas edited by Jeanna Bryner Yoga mats can be made out of the synthetic rubber neoprene, natural rubber and other materials. zoranm/Getty Images The Trump administration may soon drop a federal lawsuit against a Louisiana petrochemical plant to reduce its emissions of chloroprene, a cancer-causing chemical that has been at the heart of a roughly decade-long environmental justice battle. Chloroprene is a volatile liquid made of chlorine and carbon atoms. When its molecules are linked together to form chains in a process called polymerization, they form polychloroprene—better known as neoprene, a common synthetic rubber that is widely used in wetsuits and other protective gear. Neoprene is relatively inert and resists degradation, and it is used in clothing, masks and accessories. But during neoprene’s production, the crucial ingredient chloroprene can enter the air because of its volatility. An early reported occurrence of high occupational exposure to chloroprene occurred in 1973, when airborne concentrations of the chemical reached up to 24,470 micrograms per cubic meter (24,470 µg/m3) within one manufacturing plant that was monitored by scientists. Chloroprene’s carcinogenic risk was first noted in the 1970s, when exposed workers started turning up with high rates of cancer. A 1978 study on 234 male neoprene plant workers in the U.S. found 12 deaths from cancer over a 15-year period, three deaths more than would be expected compared to the rate among the company’s workers as a whole. The rate of cancer of the urinary organs in particular raised red flags: Five of the exposed men died of such cancers over 15 years, far higher than the expected rate of one death every 30 years for a similar population that was not exposed to chloroprene. Research on exposed workers in shoe manufacturing factories in Russia linked chloroprene exposure to liver cancer, kidney cancer and leukemia. If you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today. Animal studies have also shown that either ingesting or inhaling chloroprene can cause cancer. In 2010 the U.S. Environmental Protection Agency identified the chemical as a likely human carcinogen. According to the studies the EPA reviewed in that analysis, chloroprene is probably a mutagen—an agent that can damage DNA or trigger genetic mutations. The EPA set a maximum allowed chloroprene exposure level at 0.2 µg/m3 over 70 years in an attempt to keep the additional cancer risk from exposure below 100 cases per every million people. In 2023 the agency filed a lawsuit against the only plant that emits chloroprene in the U.S.: a former DuPont site that is now owned by the Japanese company Denka in Reserve, La. According to the lawsuit, monitoring found that this Denka Performance Elastomer plant consistently released up to 14 times the maximum allowed amount of chloroprene in the surrounding community. Now the New York Times has reported that the Department of Justice is likely to withdraw that lawsuit as part of its move to axe environmental justice programs. Census Tract 708, where the plant is located, is about 91 percent Black. “I’m upset, and I just cannot sleep at night,” says Robert Taylor, who was born in Reserve in 1940. Taylor is the founder of Concerned Citizens of St. John, an advocacy group he started in 2016 after learning about the health dangers of chloroprene. “I remember the suffering of my mother with the cancer. My wife got the cancer; my sister got the cancer; my brother [did]. I look around me, at my neighbors. It is a nightmare.” Reserve sits in “Cancer Alley,” a corridor of petrochemical plants where cancer rates are particularly high. While some advocates for industry blame residents’ health behaviors for these high rates, a 2022 study in the journal Environmental Research Letters found that after controlling for occupation, smoking and obesity, cancer incidence was higher in census tracts with more exposure to toxic compounds in air pollution. And these highly exposed populations were more likely to be predominantly Black. The U.S. national cancer rate is about 440 cases each year per 100,000 people in the same age range as Louisiana’s population, says Kimberly Terrell, the study’s lead author and a research scientist at the Tulane Environmental Law Clinic. Louisiana averages higher than that, Terrell says— around 480 cases per 100,000 people per year. In Cancer Alley, though, the numbers look even worse. “The most polluted census tracts that we looked at had an average overall rate above 500,” Terrell says. There is also evidence tying the Denka plant, in particular, to cancer risk. In 2021 a study published in the journal Environmental Justice found higher cancer incidence closer to the plant. The study researchers surveyed households within a 1.5-kilometer radius of the plant and those located between 1.5 and 2.5 km from it. They then compared the reported cancer numbers in these zones with national averages of Americans, matched to age, race and sex. They found an unusually high cancer rate within the entire study area—9.7 percent of residents reported a cancer diagnosis within the past 23 years—and the rate worsened with closer proximity to the plant. “The levels of cancer in Zone 1 [near the plant] are much more unusual, compared to national cancer statistics, than the levels in Zone 2,” says Ruhan Nagra, an associate professor of law at the University of Utah, who led the study. Denka has argued that the EPA has set its limit for chloroprene exposure too low. A 2020 study partially funded by the company asserted that mice (which were used in the animal studies of the chemical) are more susceptible to cancer from chloroprene than humans and that the exposure limit should be more than 100 times higher than 0.2 µg/m3. (The lead author of that study did not respond to an interview request). In 2022 the EPA declined to change its exposure limit after an independent peer review of Denka’s toxicology claims, with reviewers finding that the company’s methodology did not support it assertions of reduced cancer risk. A lawyer for Denka declined to comment on the possible withdrawal of the lawsuit. Taylor says he and his fellow advocates have felt overwhelmed by the developments. “This country has abandoned us to the vagaries of the petrochemical industry,” he says. “Who decided to sacrifice us and to whom?” Taylor adds. “Who are the beneficiaries of my three-year-old great-grandson, who, at 2.5 years old, had already exceeded the 70-year level of exposure to these chemicals? ... Me and my board of directors, we’re in emergency mode. We know we have to come together and come up with some plans. We cannot lay down for this.” Stephanie Pappas is a freelance science journalist based in Denver, Colo.
--------------------------------------------------------------------------------
URL: https://www.scientificamerican.com/article/daylight-saving-time-and-early-school-start-times-cost-the-economy-billions/
TITLE: Daylight Saving Time and Early School Start Times Cost The Economy Billions
DATE: March 7, 20255 min read
CONTENT:
March 7, 2025 5 min read Daylight Saving Time and Early School Start Times Cost The Economy Billions The current system of daylight saving time and early school start times wastes billions while causing more car accidents, workplace injuries and health issues By Joanna Fong-Isariyawongse & The Conversation US Daylight saving time kicks in on March 9, 2025. Along with the health benefits, studies have found that moving school start times to 8:30 am or later could add $8.6 billion to the economy within two years, partly by increased graduation rates. Mypurgatoryyears/Getty Images The following essay is reprinted with permission from The Conversation, an online publication covering the latest research. Investigations into the 1986 Space Shuttle Challenger disaster revealed that key decision-makers worked on little sleep, raising concerns that fatigue impaired their judgment. Similarly, in 1989, the Exxon Valdez oil spill resulted in a massive environmental catastrophe. The official investigation revealed the third mate, in charge of steering the ship, was running on too little sleep, among other problems. While these specific disasters were not caused by daylight saving time, they are conclusively linked to fatigue, based on post accident investigations and reports. They underscore the well-documented dangers of sleep deprivation and fatigue-related errors. Yet a vast body of research shows that every year, the shift to daylight saving time needlessly exacerbates these risks, disrupting millions of Americans’ sleep and increasing the likelihood of accidents, health issues and fatal errors. If you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today. Imagine a world where one simple decision – keeping our clocks aligned with the natural cycle of the Sun – could save lives, prevent accidents and improve mental well-being. It’s not just about an hour of lost sleep; it’s about how small disruptions ripple through our health, our workplaces and even our children’s futures. I’m a neurologist who specializes in sleep health. I’ve seen firsthand the negative impacts of poor sleep; it has enormous personal and economic consequences. Yet despite overwhelming research supporting better sleep policies– such as delaying school start times to align with adolescent biology and the adoption of permanent standard time – these issues remain largely overlooked in public policy discussions. Chronic sleep deprivation does more than leave people tired. It costs an estimated US$411 billion annually in lost productivity and health care costs. Poor sleep leads to workplace mistakes, car accidents and long-term health issues that strain businesses, families and the economy as a whole. Fortunately, there’s a fix. Smarter sleep policies – such as permanent standard time and later school start times – can boost efficiency, improve health and save lives. Teenagers are the most sleep-deprived age group in the U.S. Multiple studies and surveys show that anywhere from 71% to 84% of high school students report getting insufficient sleep. This is largely due to early school start times, which force teens to wake up before their biological clocks are ready. If you have a teenager, you probably see it every day: The teen struggling to wake up before sunrise, rushing out the door without breakfast, then waiting in the dark for the school bus. More than 80% of public middle and high schools in the U.S. start before 8:30 a.m., with 42% starting before 8 a.m. and 10% before 7:30 a.m. As a result, some districts have bus pickups as early as 5 a.m. Teenagers are going through a natural shift in their circadian rhythms by about two hours. This shift, driven by hormones and biology, makes it hard for them to fall asleep before around 11 p.m. The bodies of teens aren’t wired for these schedules, yet schools and society have designed a system that forces them to function at their worst. Sleep-deprived teens have lower grades and test scores, more car crashes caused by drowsy driving, more alcohol and drug use and higher rates of depression, anxiety, suicide and aggressive behavior, including carrying weapons. Along with the health benefits, studies have found that moving school start times to 8:30 am or later could add $8.6 billion to the economy within two years, partly by increased graduation rates. While concerns about increased transportation costs exist, such as the need for additional buses or drivers due to staggered school start times, some districts have found that optimizing bus routes can offset expenses, making the change cost-neutral or even cost-saving. For instance, a study in Boston found that reorganizing bus schedules using advanced algorithms reduced the number of buses needed and improved efficiency, which allowed high school students to start later and better align with their natural sleep cycles. This change not only supported adolescent sleep health but also saved the district $5 million annually. Every March, most Americans shift their clocks forward for daylight saving time. Studies show this change disrupts sleep and leads to measurable adverse outcomes, including a significant increase in heart attacks. These effects linger for days after the shift, as sleep-deprived workers struggle to adjust. The mental health impact is also severe. Suicide rates increase in the weeks following the switch, particularly for those already vulnerable to depression. Unlike daylight saving time, standard time follows the body’s natural circadian rhythm, which is primarily regulated by exposure to sunlight. Our internal clocks are most stable when morning light exposure occurs early in the day, signaling the body to wake up and regulate key biological functions such as hormone production, alertness and metabolism. In contrast, daylight saving time artificially extends evening light, delaying the body’s release of melatonin and making it harder to fall asleep at a biologically appropriate time. Studies have found that adopting permanent standard time could prevent up to 5,000 suicides annually by reducing seasonal depression, decrease errors, injuries and absenteeism in the workplace and make roads safer, potentially preventing 1,300 traffic deaths each year. The U.S. tried permanent daylight saving time in 1974. It was so unpopular that Congress repealed it within nine months. Russia tried it too, in 2011, but switched back three years later. The United Kingdom dropped permanent daylight saving time in 1971 after three years, and Portugal in 1996 after four. All of these countries found that the switch caused widespread public dissatisfaction, health concerns, more morning car accidents and disrupted work schedules. No country is currently on year-round daylight saving time. These examples provide real-world evidence that permanent DST is undesirable due to public dissatisfaction, safety concerns and negative health effects – all three countries attempted it and ultimately reversed course. Since 2022, there has been renewed debate, largely driven by former U.S. Sen. Marco Rubio’s Sunshine Protection Act, which aims to make DST permanent. However, the name is misleading because it doesn’t “protect” sunshine but rather eliminates critical morning light, which is essential for regulating circadian rhythms. Major health organizations, along with the National Safety Council, strongly oppose permanent DST due to its well-documented risks. There are signs that suggest the U.S. is finally waking up to these problems. Out of 13,000 school districts, 1,000 have independently adopted later school start times. California and Florida have enacted laws requiring high schools to start no earlier than 8:30 a.m. California’s mandate went into effect in 2022, and Florida’s is set to begin in 2026. Permanent standard time and later school start times are not radical ideas. They’re practical, evidence-based solutions based on human biology. Implementing these changes nationally would require congressional action. However, current federal law already allows states to adopt permanent standard time, as Arizona and Hawaii have done, setting a precedent for the rest of the country. This article was originally published on The Conversation. Read the original article. Joanna Fong-Isariyawongse is an associate professor of neurology at the University of Pittsburgh. Curated by professional editors, The Conversation offers informed commentary and debate on the issues affecting our world.
--------------------------------------------------------------------------------
URL: https://www.scientificamerican.com/article/a-backyard-bird-offers-a-new-way-of-thinking-about-sexes/
TITLE: This Backyard Bird Has a Lot to Teach Us about Sex Variability
DATE: March 2025
CONTENT:
February 18, 2025 14 min read This Backyard Bird Has a Lot to Teach Us about Sex Variability White-throated Sparrows demonstrate that traits we usually associate with sex can be influenced by genes that are not on sex chromosomes By Donna L. Maney © Joel Sartore/Photo Ark It’s springtime in your backyard. You watch a pair of little brown songbirds flit about, their white throats flashing in the sun. One of the birds has striking black and white stripes on its crown and occasionally belts out its song, “Old Sam Peabody, Peabody, Peabody.” Its partner is more drab, with tan and gray stripes on its head and brown streaks through its white throat. Knowing the conventional wisdom about songbirds—that the males are flashy show-offs and the females more camouflaged and quiet—you decide to name the singer with bright plumage Romeo and the subtler one Juliet. But later that day you notice Juliet teed up on the fence, belting out a song. Juliet’s song is even louder and showier than Romeo’s. You wonder, Do female birds sing? Then you see Romeo bringing a twig to the pair’s nest, hidden under a shrub. Your field guide says that in this species the female builds the nest by herself. What is going on? Turns out, when you named Romeo and Juliet, you made the same mistake 19th-century artist and naturalist John Audubon did when, in his watercolor of this species, he labeled the bright member of the pair “male” and the drab one “female.” Romeo might look male, even to a bird expert such as Audubon, but will build a nest and lay eggs in it. Juliet, who might look female, has testes and will defend the pair’s territory by singing both alone and alongside Romeo, who also sings. If you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today. Juliet and Romeo are White-throated Sparrows (Zonotrichia albicollis). At first glance, members of this species of songbird might look rather ordinary. For example, like many other songbirds, one member of each breeding pair of these sparrows has more striking plumage—that is, its appearance is what we would traditionally consider malelike for songbirds. The other bird in the pair is more femalelike, with drabber plumage. On closer inspection, White-throated Sparrows are quite remarkable. If we were to assume that the brighter bird in each breeding pair is the male, we’d be right only half the time. In about 50 percent of breeding pairs of White-throated Sparrows, the brighter bird has the testes and the drabber bird has the ovaries, in keeping with the typical songbird pattern. In the rest of the breeding pairs, however, the bird with the more striking plumage is the one with the ovaries, and the duller bird has the testes. White-striped birds with ovaries behave in a way that is more masculine than we expect for female songbirds. Researchers have known since the 1960s that White-throated Sparrows occur in two color forms: a brighter “white-striped morph” and a plainer “tan-striped morph.” Even though morph has nothing to do with sex—birds of each morph are equally likely to have ovaries or testes—the birds still pay attention to morph when choosing mates. Whether male or female, tan-striped birds almost always choose white-striped mates, and vice versa. Each bird, therefore, chooses a mate from only 25 percent of the population; if you are a tan-striped female looking to make some babies, a male of the same morph just won’t do. You want a male with white stripes on his head. This interesting and complex situation has earned this species the nickname “the bird with four sexes.” But to be clear, White-throated Sparrows do not have four different types of gonads. As in other birds, each individual typically has either two testes that produce sperm or a single ovary that produces eggs. Nevertheless, as recent research has shown, this species has much to teach us about the nature of sex variability—the way in which sex-related behaviors are influenced by genes, the complex structure of sex-associated chromosomes and the evolution of sexual reproduction itself. Importantly, this species challenges the practice of flattening nature’s wondrous diversity into two categories, male and female. I have spent the past 25 years studying this fascinating species, trying to understand how social behavior and the structure of genomes can influence each other’s evolution. White-throated Sparrows are a particularly good model for this line of research because the categories of sex and morph are each associated with special chromosomes. The sex chromosomes, which in birds are known as Z and W, influence whether primordial gonads develop as ovaries or testes. Birds with both the Z and the W typically develop an ovary, whereas birds with two copies of the Z develop testes. Color morph is associated with a different chromosome, chromosome number 2. Like sex chromosomes, chromosome 2 in White-throated Sparrows occurs in two versions. The first, which we’ll call the standard version, was the first to be sequenced by scientists. The other is a rearranged version that contains a “supergene,” which is technically a collection of genes bound together. Whether male or female, birds with a copy of the supergene develop as white-striped; birds with only the standard chromosome develop as tan-striped. Rebecca Gelernter; Source: “Multivariate Models of Animal Sex: Breaking Binaries Leads to a Better Understanding of Ecology and Evolution,” by J. F. McLaughlin et al., in Integrative and Comparative Biology, Vol. 63; October 2023 (reference) Although color morphs in White-throated Sparrows are not technically sexes, the standard and supergene-bearing versions of chromosome 2 share features with the human sex chromosomes X and Y, respectively. In a typical breeding pair, one bird has two copies of the standard version, analogous to the XX genotype in humans. The other bird has one copy of the standard and one copy of the supergene, analogous to the XY genotype. Just as humans with two Y chromosomes are rare, the number of White-throated Sparrows with two copies of the supergene is vanishingly small. Almost all birds of the white-striped morph have one standard version of chromosome 2 to pass down and one version with the supergene. As a result, half the offspring of each breeding pair will inherit the supergene, and half will not. The supergene-bearing version of chromosome 2 resembles the mammalian Y chromosome in other ways. To understand the similarities, let’s consider how it came to exist. Geneticist James W. Thomas, who was then at Emory University, and his laboratory demonstrated that the supergene itself is made up of several inversions—large sections of DNA sequence that long ago flipped 180 degrees relative to the standard sequence. The rearranged region on chromosome 2 in White-throated Sparrows is so large that the two different versions cannot line up precisely beside each other and swap genes, a process known as recombination. Generally speaking, mismatched sequences aren’t a big problem, so long as there is another copy of the same version of the chromosome nearby to line up and swap genes with. But for the supergene version of chromosome 2, there usually isn’t one. As is the case for the mammalian Y chromosome, individuals with the supergene chromosome typically have only one copy of it. So, whereas in the tan-striped birds the two copies of the standard version of chromosome 2 can recombine freely with each other, in white-striped birds the supergene version of the chromosome stands alone, unable to recombine with a partner. This isolation has caused the gene sequences inside the supergene to slowly diverge from the corresponding sequence on the standard version, becoming less and less similar to it over time. Escaping recombination also causes the genes inside the supergene to become locked together, meaning that each white-striped bird inherits a large block of increasingly differentiated genes. For these sparrows, those differentiated genes translate to differences in plumage and behavior. The evolutionary changes taking place in chromosome 2 in White-throated Sparrows loosely recapitulate a classical theory of the evolution of sex chromosomes. In the case of the X and Y chromosomes in mammals, suppression of recombination has been hypothesized to cause progressive loss of gene function and even the loss of entire genes. Over time the Y chromosome has degenerated such that it shares only a handful of genes with the X. The same scenario has played out for sex chromosomes in a wide variety of species, including other mammals, birds and many insects: a chromosome associated with either testicular or ovarian development has stopped recombining with its former partner and has differentiated substantially. The supergene-bearing chromosome 2 in White-throated Sparrows seems to be in the same situation. To investigate these parallels more closely, we worked with researchers at the Georgia Institute of Technology, led by Soojin V. Yi. Our study revealed that the supergene shows only minimal signs of degeneration. Thus, although the chromosome with the supergene may be recapitulating the evolution of a sex-chromosome-like system in many ways, we don’t see obvious evidence that it will end up small, like the Y, anytime soon. In White-throated Sparrows, both white-striped birds (bottom) and the drab tan-striped birds (top) sing. Glenn Bartley/Minden Pictures (top); Scott Leslie/Minden Pictures (bottom) The White-throated Sparrow’s chromosome 2 also resembles the mammalian XY chromosome system with respect to its consequences for behavior. Birds with the supergene version—that is, the white-striped birds—defend their breeding territories more vigorously on average than do their tan-striped counterparts, who spend more of their time bringing food to offspring in the nest. In other words, behaviors we expect to be associated with the Y chromosome in mammals—namely, prioritizing territorial aggression over parental care—have become associated with the supergene even though the supergene is not located on a sex chromosome. These behaviors have become dissociated from the gonads. This dissociation makes this species especially valuable for understanding the evolution of sex-related traits and the extent to which any individual can be said to be one sex versus another. In White-throated Sparrows, we see “masculine” and “feminine” traits distributing themselves in a manner clearly orthogonal to gonadal sex. White-striped birds with ovaries behave in a way that is more masculine than we expect for female songbirds, and tan-striped birds with testes look and behave in a relatively feminine way. Because the behavioral differences between the morphs can be attributed to a genetic sequence not associated with sex or sex chromosomes, the supergene provides an important tool with which to identify gene variants that nudge a sparrow in one behavioral direction or another no matter what gonads it has. Twentieth-century geneticist Theodosius Dobzhansky, who once said, “Nothing in biology makes sense except in light of evolution,” speculated that inversions are adaptive because they capture and bind together gene variants that confer a collective benefit when inherited together. The inversions that make up the White-throated Sparrow supergene have captured about 1,000 genes that are slowly differentiating from the standard versions—certainly a rich source of possibilities for co-adaptation. In my laboratory at Emory, we went on the hunt for gene variants inside the supergene that shift the behavior of the white- and tan-striped sparrows in masculine and feminine directions, respectively. We knew that circulating levels of steroid hormones—namely, testosterone in males and estradiol in females—are higher in white-striped than tan-striped birds. This morph difference in hormone levels does not, however, explain the differences in their behavior. When we experimentally equalized levels of steroid hormones between the morphs, the white-striped birds were still more aggressive, despite having levels of steroid hormones identical to those of the tan-striped birds. Perhaps the white-striped birds are simply more sensitive to their own circulating steroids. If so, we wondered, what is the biology underlying that sensitivity? To answer that question, Brent M. Horton and I led a team to take a neuroscience approach. We reasoned that increased sensitivity to steroid hormones in white-striped birds might come from higher levels of the receptors for those hormones in their brains. Sure enough, in a part of the brain associated with reproductive behaviors, white-striped birds have extraordinarily high activity of a gene encoding a steroid-hormone receptor important for territorial aggression. This gene, called ESR1, is located inside the region of chromosome 2 that corresponds to the location of the inversions. Over evolutionary time the variant of ESR1 inside the supergene has diverged genetically from its counterpart on the standard chromosome. This genetic divergence has revved up the activity of the supergene variant such that white-striped birds have higher levels in this brain region than do tan-striped birds. Moreover, the more active the supergene variant of ESR1 relative to the standard version, the more aggressive the bird. We had our smoking gun. To show definitively that this receptor plays a causal role in white-striped aggression, Jennifer R. Merritt, then a graduate fellow at Emory, led an effort to experimentally manipulate the molecular products of the ESR1 gene. We hypothesized that if white-striped birds were more aggressive because of higher levels of the hormone receptor, then the morph difference in aggression should disappear if we experimentally reduced production of the receptor in those birds down to the tan-striped level in the brain region in question. Just as we predicted, white-striped birds with reduced receptor levels showed no more aggression than tan-striped birds. In other words, we were able to change their behavior from white-striped to tan-striped by altering the activity of a single gene. As exciting as that finding was, we were under no illusion that the aggressive behavior of the white-striped morph can be explained by just one gene. We believe, as Dobzhansky would have, that the behavior is influenced by multiple, co-adapted genes inside the supergene. Our analysis of all the genes inside the supergene, spearheaded by Emory researcher Wendy M. Zinzow-Kramer, showed that ESR1 is part of a large network of genes inside the supergene that predict territorial aggression. Perhaps these genes act together somehow to alter both plumage and behavior. White-throated Sparrows help us see past the sex binary by forcing us to acknowledge sources of variability other than sex. Armed with the knowledge that the neighbors of influential genes can have related functions, we directed our attention to a gene that is practically adjacent to ESR1 inside the supergene. This gene, known as VIP, is active widely in the brain and influences a variety of social behaviors across vertebrates. In songbirds, it promotes aggression when activated in one part of the brain and parental behavior in another. Because these behaviors are the ones that differ between the morphs in White-throated Sparrows, this gene was a prime candidate for further investigation. Horton and his team showed that in the brain region where VIP is associated with aggression, activity of the VIP gene is higher in the white-striped morph. In the brain region associated with parenting, its activity is higher in the tan-striped morph. Because white-striped birds are more aggressive and tan-striped more parental, this finding strongly suggested a role for VIP in the behavioral differences. But how can the same gene variant be revved up in one brain region and ramped down in another? A group led by Mackenzie R. Prichard, then a graduate fellow at Emory, provided an important clue. The VIP variant inside the supergene differs from the standard version not only genetically but also in another important way. DNA can be tagged with chemical markers that are not part of the gene sequence—they attach to it epigenetically, which can silence the gene. In the brain region where VIP promotes aggression, these tags are significantly reduced on the supergene variant of VIP. Although we do not totally understand the mechanisms that regulate the tags, their removal from the supergene probably allows the peptide that VIP encodes to be produced at higher levels in this brain region in the white-striped birds. The situation looks different in the brain region associated with parenting, where the relative activity of the supergene variant of VIP is significantly lower. The 19th-century artist and naturalist John Audubon mistakenly assumed that the whitestriped variants of the White-throated Sparrow were all males and the tan-striped birds were all females. Fine art images/Heritage Images via Getty Images These findings are exciting because they show that production of the VIP peptide is regulated differently in each of these two brain regions in ways that are adaptive for each morph. In the brain region where VIP promotes aggression, the brakes have come off the supergene version of the gene. The resulting higher activity may allow the white-striped birds to produce more VIP peptide where it is needed for aggression. In the region where VIP promotes parental behavior, the brakes are applied a bit more to the supergene, which may reduce VIP production in this region in white-striped birds and make them less parental. Is it significant that the two supergene variants of ESR1 and VIP are so close to each other inside the supergene? Are they co-adapted at the molecular level? We don’t yet know. Even if the gene products don’t interact directly, both contribute toward the same aggressive, white-striped phenotype. Dobzhansky might argue that this shared function alone makes their linkage adaptive. Over evolutionary time the supergene is likely to accumulate even more gene variants and epigenetic tags that complement an aggressive phenotype, in keeping with the theory behind the evolution of chromosomes associated with sexes. White-throated Sparrows demonstrate that traits we usually associate with sex can be influenced by genes that are not on sex chromosomes. In this species, some of those genes are linked to one another and to an obvious, sex-adjacent phenotype, making these associations easy to study. But the dissociation of sex-related genes from sex chromosomes isn’t at all exceptional. In all sexually reproducing species, including humans, most genes that contribute to sex-related variation are not known to be linked to any particular genomic architecture. Even genes involved in gonadal development and hormone synthesis can be found on most any chromosome, mapping to locations throughout the genome that freely recombine. Each individual inherits a new combination of genetic and epigenetic material, resulting in diversity that defies binary categories. In most sexually reproducing species, making an embryo requires two gametes: one egg and one sperm. That binary is clear. But the egg-sperm binary does not apply to the eventual development of that embryo into a sexed body with sex-related behaviors. That development is conceptually separate and decidedly nonbinary in many ways. To understand why, let’s consider the theoretical evolutionary function of sexual reproduction. Biologists have long argued that the genetic function of sex—namely, the mixing of genomes in the generation of offspring—is to create combinations of genes that could confer advantages in an unpredictable future environment. Sexual reproduction hurries the new combinations along, meaning the advantageous combinations become established much faster than if we simply cloned ourselves and waited for genes to randomly mutate into more beneficial forms. In other words, the entire point of having sexes is to generate diversity. Each new organism possesses a genome never seen before, unlike either parent’s. For reasons that so far remain mysterious to scientists, the most diverse traits are those that relate to reproduction itself. Beyond White-throated Sparrows, the diversity of sexual phenotypes across species is vast and spectacular. Even though embryos in most any sexually reproducing species are typically made from one egg and one sperm, the development of sexed bodies is characterized by profound flexibility and plasticity. Many fish change their gamete production from eggs to sperm, or vice versa; some worms produce both at once; some lizard species produce no sperm at all. In many reptiles, whether an embryo develops ovaries or testes is determined by the temperature at which the eggs are incubated, not by genetic code. The natural world is a parade of heterogeneity in sexual form and function. Until recently, species such as sex-changing fish, all-female lizards and White-throated Sparrows with their “four sexes” were regarded as curiosities—oddball organisms that seemed to break the rules. But that view is rapidly changing. New tools for studying the processes underlying sexual development call the rules themselves into question. We are learning that the molecular pathways that guide a body to develop ovaries, testes, or other sex-related features are evolutionarily unstable and precarious. The genes and proteins that contribute to making a gonad are not the same across species, even closely related ones. These pathways are not well conserved, suggesting they remain flexible for good reason. The development of sex-related traits is astonishingly diverse not only across species but within them. Every individual, sparrow or human, has masculine and feminine characteristics. That diversity is obscured when we lump individuals into two categories and consider each as a homogeneous group. When we compare the categories “female” and “male,” we often report a “sex difference”—a binary outcome made inevitable by a binary approach. This approach fails to acknowledge the profound overlap between sexes on almost any measure. White-throated Sparrows help us see past the sex binary by forcing us to acknowledge sources of variability other than sex, which is, in reality, only a small contributor to variability for many species. Diversity and plasticity of phenotypic expression is the norm, particularly for traits that correlate with sex. Sex-related traits are simply not hardwired. Evolutionary biologists believe that this plasticity—like the dazzling diversity of sex-determining molecular pathways—may be adaptive in changing environments. Individuals retaining maximal flexibility in the expression of sex-related traits are better able to adapt quickly to changing environments or, in some cases, may even be able to change their sex. Sexual reproduction, by its very nature, generates diversity. The different pathways by which bodies develop as male, female, both or neither are perhaps as numerous as species themselves. Genomes are fluid, constantly changing and evolving. Gene sequences link together and separate in a never-ending dance. The environment also changes constantly, guiding development in unpredictable and sometimes disruptive ways. Every newly evolved avenue to develop into a sexed body begins a new, generative process that gives rise to still newer routes. Viewed this way, it is clear that sexual diversity within species is an evolutionary adaptation—a feature, not a bug. Like our backyard sparrows Romeo and Juliet, each of us is expressing our own unique phenotype just as nature intended. Beyond XX and XY. Amanda Montañez; September 2017. ScientificAmerican.com/archive Donna L. Maney is a neuroscientist at Emory University. Her current research focuses on how sex and gender are treated as variables in biomedical research.
--------------------------------------------------------------------------------
URL: https://www.scientificamerican.com/article/company-seeking-to-resurrect-the-woolly-mammoth-creates-a-woolly-mouse/
TITLE: Company Seeking to Resurrect the Woolly Mammoth Creates a ‘Woolly Mouse’
DATE: March 4, 20256 min read
CONTENT:
March 4, 2025 6 min read Company Seeking to Resurrect the Woolly Mammoth Creates a ‘Woolly Mouse’ On its quest to bring back the extinct woolly mammoth, Colossal Biosciences has developed the woolly mouse By Adam Popescu edited by Andrea Thompson The "woolly mouse" was developed by Colossal Biosciences by editing genes to give the mouse a bushier, thicker coat, akin to that of the extinct woolly mammoth. Colossal The biotech company Colossal Biosciences has long aspired to bring back the extinct woolly mammoth, which roamed the Northern Hemisphere thousands of years ago, during the last ice age. But for now, as a step along the way, the company has come up with something decidedly less mammoth: meet the woolly mouse. On Tuesday Colossal announced this lab-born animal, which features shaggy, mammothlike fur and has cold-adapted traits such as the way in which it stores and burns fat. Researchers retrieved and sequenced ancient mammoth DNA from preserved skin, bone and hair to learn which genes controlled traits such as coat color and cold tolerance. They altered the corresponding genes in lab mice and made other alterations in the rodents’ genome. What was the purpose of this feat of genetic engineering? Colossal’s pitch is that, with biodiversity going the way of the dodo (which the company also hopes to resurrect), saving existing species will require tweaking their DNA to make them more resilient. The researchers at the company also claim that bringing back extinct species can help the environment. For example, they say that mammoths can help fight climate change by tamping down Arctic permafrost, reducing how much of it is thawing and releasing methane into the atmosphere. Company co-founder and CEO Ben Lamm puts the approach in startling terms: “Why leave nature to chance?” In pursuit of such “de-extinction” goals, Colossal has raised hundreds of millions of dollars from everyone from celebrities to the CIA. If you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today. But many experts in genetic engineering and conservation are skeptical. Rewilding is risky; species such as wolves and elephants have come into conflict with humans, and others have fallen victim to predators and poachers. No one knows what would happen if a mammoth—or, more technically, an elephant-mammoth hybrid—was released: What would it eat? How would we protect it? Could it reproduce? As for saving the climate, "we’re looking at a warming world, and [Colossal’s researchers] want to bring back creatures that are adapted to the cold?" says Elsa Panciroli, a paleontologist at National Museums Scotland, who studies ancient mice-sized mammals. “I study animals from the past, and they should stay in the past. Lack of habitat, human conflict, agriculture, climate change—the idea that they can fix that with gene editing is missing the big picture.” Colossal was co-founded in 2021 by Lamm, who made billions of dollars by founding tech companies, according to Forbes, and Harvard biologist George Church. In 2024 Colossal announced it had created elephant stem cells, which can be reprogrammed to become specific tissue—such as egg cells. Colossal says mass-produced elephant egg cells are vital for conservation breeding programs and will be needed to clone any future elephant-mammoth hybrids. The woolly mouse is the latest development to emerge from that quest. (Mice are much easier to work with than elephants.) In a statement issued this week, Colossal’s chief science officer Beth Shapiro called the news “an important step toward validating our approach to resurrecting traits that have been lost to extinction.” Colossal’s team used standard techniques to target different genes in the mouse genomes to create mammothlike hairs, patterns and color, producing “mice with long hair, enhanced waviness and altered coat texture,” according to a preprint research paper by the company that has not yet been peer-reviewed. “We used the ancient DNA to identify the genes we were interested in working with,” Shapiro says. “We looked for mice that have genetic variation in those same genes we identified using ancient DNA, and we then put those particular mouse variants together.” A mouse gene altered with an ancient mammoth gene variant, or allele, that affects keratin (a protein found in hair and nails) was inserted into the mice to alter hair texture—specifically waviness. “It puts the mammoth version of that allele in the mouse,” Shapiro explains. The team also targeted lipid metabolism, “which is the process by which the body breaks down, synthesizes and stores fats,” Shapiro says. The paper notes that “future experiments will examine the effect of high fat diets and temperature preferences” on the mice to inform further work toward the goal of developing cold-adapted elephant-mammoth hybrids. Other experts say putting DNA from an extinct species into a living one is an accomplishment, but they still wonder: Why make a mutant mouse at all? Gene editing has a high rate of failure, often killing surrogates and offspring, notes Robert Klitzman, a Columbia University bioethicist who questioned the value the woolly mouse beyond a “wow” factor. Not all of the genetically modified mouse embryos led to successful pregnancies, Shapiro says, but “every mouse that was born is still alive.” (The mice were born in mid-October 2024.) She adds that “our mice have enhanced living conditions and are under the full-time care of our veterinary staff. All of our work is overseen by and must be preapproved by an external ethics board [the Institutional Animal Care and Use Committee], and only trained scientists interact with the mice.” And if a mouse were to somehow escape the lab, the potential biological implications pose another concern because the animal could mate with members of wild populations. “Anyone who's kept pet mice knows they can get out through very small holes," Panciroli says. “In certain ancient species’ DNA, you don’t know what the function of this DNA is, so there are more than ethical problems; there are biological hazards from moving and editing the DNA,” says Yale University geneticist Jiangbing. Zhou “I’m not sure about the potential risks of this type of work, as the function of ancient DNA in live mice may be difficult to predict.” Shapiro points to the genetic mutations that happen naturally with reproduction and notes that most of these have no impact. “Genetic changes are not, in and of themselves, a cause for concern. That said, we are selecting genetic variation that we intend to have an impact on the way the organism looks or acts, and so more caution is necessary,” she says. “Our approach is to evaluate the impact of edits in as many ways as possible before making them.” The company also says all of the engineered mice born so far are male—and there are no plans to breed them. What happens with the mice or—if the company ever realizes its ultimate ambition—the woolly mammoths is another ethical quandary. "I feel like Jeff Goldblum in Jurassic Park, but if we’re going to interfere with nature, there has to be good reason,” Panciroli says. Additionally, reintroduced animals (including elephants) are routinely targeted by poachers, points out Andrea Crosta, founder of a wildlife-crime-fighting nongovernment organization called Earth League International. Craig Callender, who studies science ethics as a professor of philosophy at the University of California, San Diego, predicts this news will divide scientists. “The fact that the mice are alive, and that traits can be controlled by the genes [the Colossal researchers have] modified, makes it potentially a great tool” for genetic engineering, he says. “But if the mammoth is the end goal, it’s a stunt” because he doesn't think such a project it has inherent value. In response, Shapiro says, “Some people argue that our whole company is a stunt. While we respectfully disagree, we'd also like to point out the attention that our work draws from kids, students, and other members of the public who are inspired by what we are doing to become scientists, to think more about the impact that they can have on biodiversity, and to feel hopeful about the future.” Shapiro contends that gene editing can and should be used alongside more traditional conservation approaches. “Habitats around the planet are changing at a pace that is faster than evolution by natural selection can keep up,” she says. “Gene editing could be used to help species become resistant to disease, to restore missing genetic variation or to correct gene sequences that lead to genetic disease but have become fixed in that population.” But others are not convinced, especially by the creation of organisms such as the woolly mouse. “It’s arrogance,” says Sue Lieberman, vice president of international policy at the Wildlife Conservation Society, who spent decades fighting whaling and the ivory trade. “I’m not against technology. I’m not saying nature’s perfect. But this is such a waste of money when conservation is dying for lack of funds. To make some strange animal we can gawk at—we should be past that.” Trailblazing biologist George Schaller agrees. “We need to protect what we have,” he says. Adam Popescu is a writer and journalist based in Los Angeles. Visit his website at adampopescu.com.
--------------------------------------------------------------------------------
URL: https://www.scientificamerican.com/article/inside-the-ai-competition-that-decoded-an-ancient-scroll-and-changed/
TITLE: Inside the AI Competition That Decoded an Ancient Herculaneum Scroll
DATE: April 2024
CONTENT:
March 19, 2024 17 min read Inside the AI Competition That Decoded an Ancient Herculaneum Scroll The Herculaneum scrolls, charred and preserved by the eruption of Mount Vesuvius, were unreadable—until now By Tomas Weber Kenn Brown/MondoWorks On a warm Saturday night at the end of August in 2023, Luke Farritor, then an undergraduate at the University of Nebraska, was sitting alone in a corner at a house party in Omaha when his iPhone pinged. The music was booming, and Farritor, 21 years old at the time with a boyish face and black rectangular glasses, was surrounded by other students drinking and mingling. He opened the message. It was from Ben Kyles, a computer scientist and pianist from British Columbia, then in his mid-40s. Farritor knew Kyles as “Hari Seldon”—his online avatar, named for a character in Isaac Asimov’s Foundation series. Kyles had some news to share. He had just finished digitally unrolling some high-resolution scans of carbonized papyrus. He’d uploaded the images, he said, to a shared server. “Dude,” Farritor replied, “this is ­awesome. I’ll run it very soon.” Kyles’s papyrus was from Herculaneum, an ancient Roman town on the Bay of Naples, at the base of Mount Vesuvius, that is home to the only preserved library from classical antiquity. The collection of papyri—from which about 1,800 mostly unreadable scrolls and fragments have so far been extracted—was interred under 60 feet of material deposited by pyroclastic flows, at temperatures greater than 900 degrees Fahrenheit, during the same eruption that destroyed Pompeii in C.E. 79. Without enough oxygen to burn, the scrolls were baked into charcoal—a blessing because it allowed them to join the small trove of papyri that has managed to endure since antiquity, all of it protected from humidity in some way or another, whether inhumed in Egyptian sands or singed by fire. But it also means they cannot be unrolled without turning to dust. Using his phone, Farritor, who had been working late nights attempting to decipher the scrolls for most of the preceding six months, remotely dialed in to his desktop computer in his dorm room in Lincoln, an hour’s drive away. He located Kyles’s new papyrus segment on the server and immediately fed it into the artificial-intelligence-powered detector he had been building over the past few weeks. The detector was programmed to find ink, and therefore letters, and therefore words. He booted up the program to let it run, and he put his phone away. As the designated driver, he waited for the party to finish so he could deliver his friends back to their dorms. If you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today. The preserved papyri in Herculaneum are our best shot at rescuing lost works. For four centuries monks and princes, papyrologists and archaeologists, classicists and computer scientists have struggled to little avail to detect any letters or words inside the scrolls—which resemble saggy little brown burritos—without destroying them in the process. If we could read them, as classicists and papyrologists have long hoped to do, we might discover lost works of classical literature or philosophy or records of history and science. Perhaps they contain tragedies by Sophocles or Aeschylus or the lost writings of Livy. “The possibilities,” says David Blank, a professor of classics at the University of California, Los Angeles, “are enormous.” Almost all classical literature has come down to us from medieval monks, choosy in what they resolved to copy. As a result, relatively little “original” writing from antiquity exists, which means classical literature, from our point of view, is a panorama seen through a pinhole. We have seven plays by Aeschylus, but we know the tragedian wrote at least 10 times more than that. The preserved papyri in Herculaneum are our best shot at rescuing lost works, and some classicists suspect that even more texts could remain in areas of the villa yet to be excavated. “Who knows what’s there?” says Annalisa Marzano, a professor of classical archaeology at the University of Bologna and a trustee of the Friends of Herculaneum Society. In addition to works by the big hitters such as the poets Virgil and Horace, there’s also the tantalizing possibility of finding writing from authors “we know absolutely nothing about,” Marzano says. Hundreds of papyrus scrolls in the ancient city of Herculaneum were preserved after the eruption of Mount Vesuvius. For thousands of years, no one could open them without doing irreparable damage. Courtesy of EduceLab/University of Kentucky After dropping off his friends, Farritor parked outside his dorm and, walking toward his building, took his phone out of his pocket. He unlocked the screen. He halted. “Holy cow,” he said. The AI had outputted something. On the phone’s screen, set against the grayscale crisscross texture of woven papyrus, were three black lowercase Greek characters arranged in clear sequence. They were fuzzy but unmistakable: pi (π), omicron (ο), rho (ρ)—“πορ.” The first person in almost 2,000 years to see those letters glimpsed them late on a summer night in a parking lot in Lincoln, having salvaged them from an ancient eruption. “I freaked,” he told me when we spoke. He sent a screenshot to his mom. It was a stunning beginning. But what, Farritor wondered, was the word containing those letters? And which lost book housed that word? As the AI industry exploded in the spring of 2023 with the release of GPT-4, so did anxiety about superintelligent AI. Many “doomer” developers and thinkers in Silicon Valley and beyond warn that a system could someday choose to reduce our civilization to dust and rubble with the force of numerous Vesuviuses. This concern makes it all the more poignant that hundreds of amateur decipherers have decided to spend their time building AI in the hopes of glimpsing never before seen writings found in a city that went extinct in the wake of a terrible catastrophe. The Vesuvius Challenge, also launched in 2023, is a competition to rescue the knowledge in these scrolls. For Ahron Wayne, a Michigan-based industrial CT engineer who has participated in the challenge, the mission, he says, is about “as close as you can get to a video game.” In the 2023 contest, none of the strongest contenders had any expertise in classics. Most had only a passing interest in, and very little knowledge of, the ancient world. Most spoke no Latin, no Greek. It is the technical problem that caught their interest—that and the Vesuvius Challenge’s collective prize of more than $1 million, which was donated by some of Silicon Valley’s most powerful players. The competition was the brain wave of Nat Friedman, a Bay Area investor. Until 2021, Friedman was CEO of GitHub, Microsoft’s open-source software-development platform. Together with Daniel Gross, his longtime investment partner, he was an early financier of today’s AI windfall. In the 2010s Friedman and Gross wrote checks to machine-learning researchers, and later, when the field exploded, they started funding AI companies. Today, to train the AI models they’ve bet on, the pair possess more Nvidia AI chips than most countries. Perhaps you’ve heard that tech billionaires are planning to build a utopian city from scratch on farmland north of San Francisco; Friedman has plowed his money into that project, too. In the spring of 2020, though, with much of the world in shutdown, Friedman was hoping simply to take his mind off the plague. High-energy scans allow scientists to virtually unwrap the scrolls into 3-D images, so that AI tools can be applied to look for invisible patterns in the ink. Courtesy of EduceLab/University of Kentucky Quarantined at home in San Francisco and newly fascinated by ancient Rome, Friedman was reading Wikipedia articles about ancient disasters and calamities. In 1709, he learned, workers in the town of Resina near Naples were digging a well. At around 60 feet down their spades hit the remnants of an enormous theater. The building, which seated 2,500 people, was filled with statues of horses and noblemen. They must have been stunned. The existence of Herculaneum, the ancient town underneath their feet, had long ago slipped from collective memory. Over the next few decades a succession of military engineers, desperate for ancient artworks to decorate their own villas, gave orders to dig underground tunnels fanning out from the theater. This activity caused severe damage. Conservation-oriented archaeological methods had yet to be developed, and one Spanish military engineer, in the words of 18th-century art historian Johann Joachim Winckelmann, “knew as much of antiquities as the moon knew of lobsters.” In 1750 Karl Weber, a Swiss engineer, discovered a lavish villa by following an underground wall. The oceanfront property probably once belonged to the father-in-law of Julius Caesar, Lucius Calpurnius Piso Caesoninus. In a corner of the building, workers discovered a pile of black, misshapen cylinders a few inches high. The objects were initially thought to be carbonized wood, and some were thrown away—until Weber realized the room was a library. The workers removed more than 1,000 papyrus rolls and fragments, which were placed in a local museum. The prospect of finding an unknown work of literature in the stash captivated much of Europe, and experimentalists tried various approaches to reading the papyri. A museum curator vertically sliced through a few scrolls with a knife, scraping off layers. This brutal method uncovered some legible text, but it ruined the scrolls. An Italian prince who had recently invented a waterproof cape for the future king of Spain immersed a few scrolls in mercury, hoping the liquid metal would separate the pages. It destroyed them. Others tried exposing them to a foul-smelling “vegetable gas” or slathering the rolls in rosewater. In 1753 Antonio Piaggio, a monk who oversaw the ancient manuscripts in the Vatican Library, was summoned from Rome. Once in Naples, he invented a machine for slowly unrolling the papyrus, attaching silk threads to the edge of the sheets and gently prizing the layers apart at a rate of maybe a tenth of an inch a day. Piaggio had some success with this method and was able to reveal works by Philodemus, who taught Virgil and was one of the Greek Epicurean philosophers who held that atoms swerving and colliding in a void created the universe. But Piaggio’s approach was as destructive as it was slow. It seemed impossible to read the more than 330 still unopened scrolls without damaging them. “How would the ancient Romans feel if they knew that 2,000 years later, we would be using particle accelerators and supercomputers to read their words?” —Nat Friedman, private investor A few centuries later Friedman read about some recent breakthroughs. A group at the University of Kentucky, led by Brent Seales, a professor of computer science, seemed to be on the edge of success. In 2019 Seales’s team had arranged for two complete scrolls to be transported in custom-made cases, along with four broken-off fragments, to the Diamond Light Source, a synchrotron particle accelerator in Oxfordshire, England. Using the synchrotron’s high-energy photons, Seales and his team took micro-CT scans of the papyri at a resolution of eight microns, about the diameter of a red blood cell. Seales’s plan was to import the synchrotron scans into a custom-designed computer program to virtually unwrap each layer of papyrus, in the hopes of revealing ink on the rendered surfaces. The carbon-based ink used on the scrolls, though, had a radiodensity similar to that of the papyrus. That meant there wasn’t enough contrast for the ink to show up in the scans. To get around the problem, Seales’s team built a machine-learning model trained on manuscripts written in carbon ink. A successful ink-detection AI model could perhaps then be applied to the virtually unwrapped surfaces of the scrolls. When Friedman read about this effort, he got an idea: perhaps Silicon Valley’s AI community could help, either by investing in the project or by offering its expertise. In 2022 Friedman invited Seales to Frontier Camp, an exclusive, furtive gathering (it has no online presence) that Friedman co-organizes and that takes place in the remote woods of northern California, where a handpicked elect of technologists—about 200 founders and CEOs—camp out in the cold for a few nights every year to throw ideas around. Seales ignored the e-mail. He’d heard of Friedman but didn’t believe the correspondence was real. Friedman, though, was tenacious—and in October 2022 Seales arrived at the spartan summer-camp venue in the redwood forest of Sonoma County. That night, in one of the camp’s wood outbuildings, Seales gave a talk to a group of machine-learning engineers. “We’re going to solve this in the next hour,” Friedman whispered to Gross while Seales was still speaking. But they didn’t—and when the event ended, Friedman and Gross were worried that Seales would return to Kentucky empty-handed. So that evening, over bourbon in the bar of Seales’s Palo Alto hotel, Friedman suggested they organize an open contest instead. “We’ll put up some money for it,” he told Seales. Matthew Twombly; Christy Chapman/University of Kentucky and Stephen Parsons/Vesuvius Challenge (consultants); Amanda T. Hobbs (background research) Seales flew home to discuss the idea with the other members of his laboratory. “We don’t want to be stupid and just give away all this work we’ve done,” said Stephen Parsons, a digital-restoration researcher who was finishing up a Ph.D. thesis on the lab’s work. At the same time, they had more ideas than they could reasonably try out by themselves. More people grappling with the problem would make it more likely the scrolls would be read, which was their ultimate goal. It was settled. They would open the project to the world. Friedman struggled to contain his enthusiasm. “Working on a very exciting and weird new side project,” he wrote on Twitter (now X). “Kind of a lifelong dream type thing.” With Friedman, the group devised the competition’s structure. There would be stages of freestanding prizes for different challenges, including detecting ink, finding the first letters in the scrolls and building useful open-source software. The deadline for entries for the grand prize—for identifying four separate passages of at least 140 characters—would be December 31, 2023. “How would the ancient Romans feel,” Friedman wrote on X on the Ides of March, the day the competition launched (which was also the day after the release of GPT-4), “if they knew that 2,000 years later, we would be using particle accelerators and supercomputers to read their words, preserve them for eternity, and whisper them into the ear of a baby god?” Shortly after the competition opened, I joined the contest’s server on Discord, a message-board platform originally built for gamers. I was one of around 400 people who also signed up in the first few weeks, and by the fall of 2023 the board was bustling with 1,428 members. The competitors had downloaded the 5.5 terabytes of scan images of two scrolls, which Seales had nicknamed Banana Boy and Fat Bastard (their real names are PHerc_Paris_3 and PHerc_Paris_4), and were discussing what to do with them. For contestants who knew serious prize money was at stake, people were tossing ideas around with surprising candor. There were two main tasks: segmentation and ink detection. To find letters, you need clean surfaces, or segments, of papyrus. Along the z axis of each scroll, from top to bottom, the researchers had taken thousands of cross-sectional x-rays. Each cross section reveals rolled-up papyrus sheets like rings of a tree, wispy white lines spiraling against a dark background. Unwrapping the rolls and extracting a flat surface takes forever. It requires using mouse clicks to mark the changing position of a sheet in every cross section. Then, bespoke algorithms stitch the individual cross sections together into a single sheet. But this is stymied by the fact that the carbonization melded some of the sheets together. Sometimes the papyrus folds back on itself, or it becomes unstuck, with one sheet becoming several and no way of knowing which surface holds the writing. “It’s fused, mushy chunks of coal,” says Kyles, who was hired by Friedman to segment full-time and share the results with the community. With the help of open-source software developed by other participants, Kyles and his team of nine-to-five segmenters were able to churn out about 0.2 square inch of papyrus surface per hour. (The length of a Herculaneum scroll can be more than 32 feet.) Spotting any ink on those surfaces, though, was a different matter entirely. To boost progress in ink detection, the organizers launched a machine-learning contest on Kaggle, an online platform for data-science competitions, with prizes totaling $100,000. The task was relatively straightforward: build a machine-learning model to detect ink in the CT scans of broken-off papyrus fragments on which writing was already clearly visible (an approach the Kentucky team had already tried with some success). An ink-detection model trained on the fragments, the organizers hoped, could then be applied to segments of virtually unwrapped papyrus. The scrolls at the center of the Vesuvius Challenge came from the only preserved library from classical antiquity. Herculaneum, an ancient Roman town on the Bay of Naples, was destroyed in the eruption of Mount Vesuvius in C.E. 79. Bildagentur-online/Getty Images A total of 2,763 competitors and teams—including a pair of students at China’s Harbin Institute of Technology, a team of archaeologists from Kyiv, a medical-imaging research group in Germany, and machine-learning engineers in Japan and South Korea—signed up. They built AIs to predict the presence or absence of ink in each voxel (the three-dimensional equivalent of a pixel) of the scanned fragments and uploaded their results. Their entries were verified against data from infrared photographs of the fragments. In the weeks leading up to the close of the Kaggle competition on June 14, 2023, a team in San Diego found itself toward the bottom of the leaderboard. Tinkering with their model in cafés across the city, the teammates noticed that the ink had saturated the papyrus more deeply in certain areas. Their model was learning to place importance on the ink’s depth—but this approach was confusing it. The researchers tweaked the model to ignore the depth of the ink, which led to better results, propelling the group to the top of the leaderboard. The depth-invariant model went on to win the ink-detection competition. But something was wrong. When Ryan Chesler, one of the team members, applied his winning model to a large section of Kyles’s virtually unrolled papyrus, known as the Monster Segment, he was disappointed. The AI was not detecting any ink at all. A model trained on the fragments, it seemed, would not work on the full scrolls. Wayne, the CT engineer in Michigan, thought he knew why. The ink-detection prizewinners “are a bunch of freaking brainiacs,” he says. But they were thinking of the conundrum as a math problem. “The real world is a little bit messier,” Wayne explains. The ink-detection models might have failed to work on the scrolls because the AI was not able to learn what carbonized papyrus looked like. Without more scans of carbonized papyrus, even the most sophisticated algorithms would struggle. More familiar with scanning objects such as rocket motors and bassoons, Wayne convinced his employer to let him use one of their state-of-the-art CT scanners in his free time. (“If someone were to win the grand prize,” he says, “they could afford almost half of one of these.”) He drew sophisticated Grecian profiles on papyrus, which he then carbonized and scanned. He shared the results with others, creating a rich store of training data. Others believed the contestants were too focused on AI. Casey Handmer, an Australian physicist in his 30s, decided to visually inspect the scans instead. “If a machine can see it, a human can see it,” he says. Most machine-learning algorithms for detecting visual features, Handmer explains, are built on human detection, and for good reason: our visual cortex is highly adept at identifying subtle patterns and textures. Handmer is the founder and CEO of Terraform Industries, a California start-up that produces carbon-neutral natural gas from sun and air, with headquarters in a mock medieval castle in Burbank. He spent hours inspecting the images, to the irritation of Friedman, an investor in Terraform, who did not approve of the CEO’s distraction. After a break to 3D print a copy of his skeleton for his own amusement, Handmer found he was becoming increasingly familiar with the visual features of the burned papyrus fibers. And in May 2023, while inspecting Kyles’s Monster Segment, he noticed something remarkable. He kept seeing a recurring texture that looked like cracked mud baked on the surface of the papyrus. After an hour or so of intense staring, he noticed an upside-down π. The cracked texture had to be ink. Handmer found more of that texture in the shape of other letters and even believed he had discovered the word “Calliope” (Καλλιόπη), the name of the Muse of epic poetry. His findings, though, failed to persuade the six papyrologists who evaluated his entry in the first letters prize in June 2023—a $40,000 contest for the first person to find 10 letters in an area of 0.6 square inch. But Handmer had discovered the first ink, for which he was awarded a prize of $10,000. By sharing his breakthrough with the community in almost real time, he prepared the way for the next big advance. Farritor, the college student in Nebraska, was interning at SpaceX in Texas when he learned about Handmer’s discovery of the cracked texture. He spent his days working on the launchpad-software team for Starship—the most powerful rocket ever made. After work, though, he was up much of the night building an AI to find more of the cracked texture. Meanwhile Youssef Nader, an Egyptian data-science graduate student at the Free University of Berlin, was working on a system that he had adapted from a successful Kaggle competition model. Both Farritor and Nader succeeded in finding letter sequences. Nader’s results were cleaner, but Farritor was faster. After finding the πορ the night of the August 2023 party, Farritor continued refining his model until it spat out a couple dozen fuzzy shapes surrounding the πορ that looked like they might also be Greek letters. In September the papyrologists inspected Farritor’s results. They realized Farritor’s πορ was the beginning of the word πορφύραc, or porphoras, the ancient Greek word for “purple.” The term is rare, says Federica Nicolardi, a papyrologist at the University of Naples who helped to confirm the word. And it is likely to be from a new text. A few weeks later the competition flew Farritor out to Kentucky for a symposium organized around the breakthrough. Afterward JP Posma, one of the organizers, handed Farritor an oversize $40,000 check, and Nader, who found the same word just a few days later, was awarded $10,000 for second place. But just as the papyrologists were arriving for the symposium, Nader executed the biggest leap forward so far: he released an image showing πορφύραc in the context of four full columns of text—a sight papyrologists had not expected to see in their lifetimes. In the columns there were other identifiable words, including the possible phrase κατά μουσικήν (kata mousikēn), meaning something like “relating to music”—which makes the scroll, according to Nicolardi, most likely a work of philosophy. One night during the symposium Farritor was seen hauling Diet Cokes up to his hotel room to help him stay awake to find other long passages. In Berlin, Nader wasn’t sleeping much, either. The $700,000 grand prize seemed closer than ever. At the end of 2023, Nader teamed up with Farritor and Julian Schilliger, a robotics student in Switzerland whose software to accelerate segmentation and map the papyrus in three dimensions had won him an earlier prize. That December, having combined their approaches, the team of three produced something astounding. Building on the work each had done individually, their AI models revealed 2,000 characters in four full columns—far outstripping the Grand Prize’s criterion of four passages of 140 characters. In early February 2024 the Vesuvius Challenge awarded them the $700,000 Grand Prize. The readable text comprises around 5 percent of the first scroll, and it is from the same text as the earlier discoveries. It is a previously unread tract, probably by Philodemus, about pleasure. Are good things in small quantities more delightful than copious good things? Not at all, the author concludes. “As, too, in the case of food,” writes the author, “we do not right away believe things that are scarce to be absolutely more pleasant than those which are abundant.” The fields of papyrology and classics are changed forever. Thanks in large part to a group of amateur AI builders, we now have tools for reading the unopened Herculaneum papyri. If the technological advances continue and can be rolled out to the many unopened scrolls, says Tobias Reinhardt, a classics scholar at the University of Oxford who helped to confirm the winning entries, “we could see a recovery of ancient texts at a volume not seen since the Renaissance.” Friedman wants more—and he isn’t stopping. When we spoke in late 2023, he said his goal for 2024 was to build on the winning team’s approach to read 90 percent of the four scrolls that had by then been scanned using high-energy physics. If successful, this would unlock the hundreds of unopened Herculaneum scrolls. But those are only the ones we know about. He ultimately wishes to persuade the Italian authorities to allow new excavations of the villa, in the hopes of digging out even more material. There were a few wrinkles to be ironed out before the process could scale. Researchers would need to find a way to automate the time-consuming and expensive manual-segmentation process. Plus, hiring a particle accelerator to scan hundreds of scrolls is too expensive, and cheaper workarounds for producing high-resolution scans would have to be found. What is most startling for papyrologists, though, is the speed at which the AI pipeline is now finding identifiable letters. Going from three letters to entire words and phrases and then columns of text, which took Farritor, Nader and Schilliger a month, usually takes papyrologists 20 years of intense study, says Gianluca Del Mastro, Nicolardi’s colleague and a professor of papyrology at the University of Campania Luigi Vanvitelli. When Del Mastro looked at Nader’s columns, Friedman noticed, he had tears in his eyes. The technology that the Vesuvius Challenge helped to develop could be adapted for deciphering other lost texts beyond the Bay of Naples, Seales says. There are plenty of enticing contenders. In 1993, 140 carbonized papyrus scrolls dating from the sixth century C.E. were discovered in a Byzantine church in Petra, Jordan. Blackened and fragile, they were considered unreadable. And tens of thousands of fragments of the Dead Sea Scrolls have never been read because so many are stuck together. They are now prime candidates for the Vesuvius Challenge’s virtual-unwrapping-to-AI-ink-detection pipeline. Ancient Egyptian mummy masks were also made of papyrus, arranged in layers coated with plaster—a material called cartonnage, essentially a kind of papier-mâché. That papyrus often contained writing, which has been difficult to decipher without destroying the plaster. Those papyri may now have an afterlife, too. In the fourth century B.C.E. Greek historian Xenophon noted on his return from Mesopotamia that there was a bustling trade in scrolls across the Black Sea. This means there are almost certainly sunken ships on the seafloor that contain boxes of papyrus rolls, according to Richard Janko, a classics professor and papyrologist at the University of Michigan. These scrolls are probably still preserved in this sea, which has exceptionally low oxygen and salinity for a marine environment. So far AI excitement has revolved mainly around neural networks learning how to chat. Yet more compelling is how they will get silent things to speak. Tomas Weber is a writer who lives in London. He has written for many publications, including WIRED, the Financial Times Magazine and the Economist’s 1843 magazine.
--------------------------------------------------------------------------------
