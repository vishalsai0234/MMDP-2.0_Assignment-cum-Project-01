{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95587463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce559763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\visha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\visha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Create directories for raw and cleaned data\n",
    "os.makedirs('raw_data', exist_ok=True)\n",
    "os.makedirs('cleaned_data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c485173d",
   "metadata": {},
   "source": [
    "Define 20 categories and 3 websites for each\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357c15a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    'technology': [\n",
    "        'https://techcrunch.com/', \n",
    "        'https://www.wired.com/', \n",
    "        'https://www.theverge.com/'\n",
    "    ],\n",
    "    'health': [\n",
    "        'https://www.health.com/', \n",
    "        'https://www.mayoclinic.org/diseases-conditions', \n",
    "        'https://www.webmd.com/'\n",
    "    ],\n",
    "    'finance': [\n",
    "        'https://www.bloomberg.com/', \n",
    "        'https://www.cnbc.com/', \n",
    "        'https://www.investopedia.com/'\n",
    "    ],\n",
    "    'sports': [\n",
    "        'https://www.espn.com/', \n",
    "        'https://sports.yahoo.com/', \n",
    "        'https://www.cbssports.com/'\n",
    "    ],\n",
    "    'entertainment': [\n",
    "        'https://variety.com/', \n",
    "        'https://www.hollywoodreporter.com/', \n",
    "        'https://deadline.com/'\n",
    "    ],\n",
    "    'science': [\n",
    "        'https://www.scientificamerican.com/', \n",
    "        'https://www.livescience.com/', \n",
    "        'https://www.nature.com/news'\n",
    "    ],\n",
    "    'travel': [\n",
    "        'https://www.travelandleisure.com/', \n",
    "        'https://www.lonelyplanet.com/', \n",
    "        'https://www.nationalgeographic.com/travel/'\n",
    "    ],\n",
    "    'food': [\n",
    "        'https://www.allrecipes.com/',\n",
    "        'https://www.epicurious.com/',\n",
    "        'https://www.bonappetit.com/'\n",
    "    ],\n",
    "    'education': [\n",
    "        'https://www.edutopia.org/',\n",
    "        'https://www.edweek.org/',\n",
    "        'https://www.insidehighered.com/'\n",
    "    ],\n",
    "    'environment': [\n",
    "        'https://www.nationalgeographic.com/environment/',\n",
    "        'https://www.nature.org/',\n",
    "        'https://www.ecowatch.com/'\n",
    "    ],\n",
    "    'politics': [\n",
    "        'https://www.politico.com/',\n",
    "        'https://thehill.com/',\n",
    "        'https://www.fivethirtyeight.com/'\n",
    "    ],\n",
    "    'fashion': [\n",
    "        'https://www.vogue.com/',\n",
    "        'https://www.elle.com/',\n",
    "        'https://www.harpersbazaar.com/'\n",
    "    ],\n",
    "    'art': [\n",
    "        'https://www.artnews.com/',\n",
    "        'https://www.artforum.com/',\n",
    "        'https://news.artnet.com/'\n",
    "    ],\n",
    "    'automotive': [\n",
    "        'https://www.caranddriver.com/',\n",
    "        'https://www.motortrend.com/',\n",
    "        'https://www.autocar.co.uk/'\n",
    "    ],\n",
    "    'business': [\n",
    "        'https://www.forbes.com/',\n",
    "        'https://www.entrepreneur.com/',\n",
    "        'https://hbr.org/'\n",
    "    ],\n",
    "    'real_estate': [\n",
    "        'https://www.realtor.com/news/',\n",
    "        'https://www.zillow.com/blog/',\n",
    "        'https://www.redfin.com/news/'\n",
    "    ],\n",
    "    'gaming': [\n",
    "        'https://www.ign.com/',\n",
    "        'https://www.gamespot.com/',\n",
    "        'https://kotaku.com/'\n",
    "    ],\n",
    "    'pets': [\n",
    "        'https://www.akc.org/',\n",
    "        'https://www.petmd.com/',\n",
    "        'https://www.thesprucepets.com/'\n",
    "    ],\n",
    "    'history': [\n",
    "        'https://www.history.com/',\n",
    "        'https://www.historyextra.com/',\n",
    "        'https://www.ancient-origins.net/'\n",
    "    ],\n",
    "    'psychology': [\n",
    "        'https://www.psychologytoday.com/',\n",
    "        'https://www.apa.org/',\n",
    "        'https://www.verywellmind.com/'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fc9e4f",
   "metadata": {},
   "source": [
    "Implement web crawler to extract text from the websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ffe0c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define headers to mimic a browser\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "def get_article_links(url, max_articles=10):\n",
    "    \"\"\"Extract article links from the main page of a website\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Look for common article patterns (a tags with href)\n",
    "        links = []\n",
    "        for a_tag in soup.find_all('a', href=True):\n",
    "            href = a_tag['href']\n",
    "            \n",
    "            # Make sure the link is an article (contains keywords or patterns)\n",
    "            article_indicators = ['/article/', '/news/', '/story/', '/post/', '/blog/']\n",
    "            if any(indicator in href for indicator in article_indicators) or re.search(r'\\d{4}/\\d{2}', href):\n",
    "                # Handle relative URLs\n",
    "                if href.startswith('/'):\n",
    "                    base_url = '/'.join(url.split('/')[:3])  # Get domain\n",
    "                    href = base_url + href\n",
    "                elif not href.startswith(('http://', 'https://')):\n",
    "                    if url.endswith('/'):\n",
    "                        href = url + href\n",
    "                    else:\n",
    "                        href = url + '/' + href\n",
    "                \n",
    "                # Only include links from the same domain\n",
    "                if url.split('/')[2] in href:\n",
    "                    links.append(href)\n",
    "        \n",
    "        # Remove duplicates and limit to max_articles\n",
    "        return list(set(links))[:max_articles]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching links from {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "def extract_article_content(url):\n",
    "    \"\"\"Extract title, date, and content from an article page\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Extract title\n",
    "        title = \"\"\n",
    "        title_tag = soup.find('h1')\n",
    "        if title_tag:\n",
    "            title = title_tag.get_text().strip()\n",
    "        \n",
    "        # Extract date (common patterns)\n",
    "        date = \"\"\n",
    "        # Look for time tags\n",
    "        time_tag = soup.find('time')\n",
    "        if time_tag:\n",
    "            date = time_tag.get_text().strip()\n",
    "        else:\n",
    "            # Look for elements with date-related classes or properties\n",
    "            date_patterns = ['date', 'publish', 'posted', 'time']\n",
    "            for pattern in date_patterns:\n",
    "                date_element = soup.find(class_=lambda c: c and pattern in c.lower())\n",
    "                if date_element:\n",
    "                    date = date_element.get_text().strip()\n",
    "                    break\n",
    "        \n",
    "        # Extract main content\n",
    "        content = \"\"\n",
    "        # Look for article tags\n",
    "        article_tag = soup.find('article')\n",
    "        if article_tag:\n",
    "            paragraphs = article_tag.find_all('p')\n",
    "            content = ' '.join([p.get_text().strip() for p in paragraphs])\n",
    "        else:\n",
    "            # Look for div with content classes\n",
    "            content_div = soup.find('div', class_=lambda c: c and any(x in c.lower() for x in ['content', 'article', 'story', 'entry']))\n",
    "            if content_div:\n",
    "                paragraphs = content_div.find_all('p')\n",
    "                content = ' '.join([p.get_text().strip() for p in paragraphs])\n",
    "            else:\n",
    "                # Just get all p tags in the body as a fallback\n",
    "                paragraphs = soup.find_all('p')\n",
    "                content = ' '.join([p.get_text().strip() for p in paragraphs])\n",
    "        \n",
    "        return {\n",
    "            'url': url,\n",
    "            'title': title,\n",
    "            'date': date,\n",
    "            'content': content\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting content from {url}: {e}\")\n",
    "        return {\n",
    "            'url': url,\n",
    "            'title': '',\n",
    "            'date': '',\n",
    "            'content': ''\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e5c82b",
   "metadata": {},
   "source": [
    "Crawl websites and store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d52c8583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e52e04db2754c1bbeb58d3fdbd8a24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing categories:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crawling websites for category: technology\n",
      "  Getting links from https://techcrunch.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: Apple’s smart home hub reportedly delayed by Siri ...\n",
      "  Extracted: Judge allows authors’ AI copyright lawsuit against...\n",
      "  Extracted: How to stop doomscrolling...\n",
      "  Extracted: US charges admins of Garantex for allegedly facili...\n",
      "  Extracted: Scale AI is being investigated by the US Departmen...\n",
      "  Extracted: ChatGPT: Everything you need to know about the AI-...\n",
      "  Extracted: Why VCs ghost founders, or reject deals and never ...\n",
      "  Extracted: Anthropic’s Claude Code tool had a bug that ‘brick...\n",
      "  Extracted: SpaceX Starship spirals out of control in second s...\n",
      "  Extracted: Google scrubs mentions of ‘diversity’ and ‘equity’...\n",
      "  Getting links from https://www.wired.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: ‘Startup Nation’ Groups Say They’re Meeting Trump ...\n",
      "  Extracted: With GPT-4.5, OpenAI Trips Over Its Own AGI Ambiti...\n",
      "  Extracted: This Russian Tech Bro Helped Steal $93 Million and...\n",
      "  Extracted: The 42 Best Shows on Netflix Right Now...\n",
      "  Extracted: The DOJ Still Wants Google to Sell Off Chrome...\n",
      "  Extracted: SpaceX’s Latest Starship Explosion Marks Two Conse...\n",
      "  Extracted: Time Your Attack: Oracle’s Lost Revolution...\n",
      "  Extracted: New Proofs Expand the Limits of What Cannot Be Kno...\n",
      "  Extracted: What’s Driving Tesla’s Woes?...\n",
      "  Extracted: Social Security Workers Aren’t Allowed to Read Thi...\n",
      "  Getting links from https://www.theverge.com/\n",
      "Error fetching links from https://www.theverge.com/: HTTPSConnectionPool(host='www.theverge.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000241920EAA90>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed'))\n",
      "  Found 0 articles, extracting content...\n",
      "Saved 20 articles for category 'technology'\n",
      "\n",
      "Crawling websites for category: health\n",
      "  Getting links from https://www.health.com/\n",
      "Error fetching links from https://www.health.com/: HTTPSConnectionPool(host='www.health.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000024192B78D90>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed'))\n",
      "  Found 0 articles, extracting content...\n",
      "  Getting links from https://www.mayoclinic.org/diseases-conditions\n",
      "  Found 0 articles, extracting content...\n",
      "  Getting links from https://www.webmd.com/\n",
      "  Found 5 articles, extracting content...\n",
      "  Extracted: FDA Approves New Treatment for Stroke...\n",
      "  Extracted: This Common Vaginal Issue Is Really an STD (Study)...\n",
      "  Extracted: How Moms-to-Be Can Maximize the Immunity They Pass...\n",
      "  Extracted: Why Step Count Remains the Most Impactful Fitness ...\n",
      "Saved 4 articles for category 'health'\n",
      "\n",
      "Crawling websites for category: finance\n",
      "  Getting links from https://www.bloomberg.com/\n",
      "  Found 0 articles, extracting content...\n",
      "  Getting links from https://www.cnbc.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: eVTOLS: Are flying cars finally becoming reality?...\n",
      "  Extracted: CNBC's Inside India newsletter: Indian consumption...\n",
      "  Extracted: Tesla shares have declined every week since Elon M...\n",
      "  Extracted: 2 big things we're watching in this week's market ...\n",
      "  Extracted: People said Naples was ‘dangerous.’ So this Britis...\n",
      "  Extracted: Treasury Secretary Bessent says economy could be '...\n",
      "  Extracted: Goodyear Tire's transformation plan is underway — ...\n",
      "  Getting links from https://www.investopedia.com/\n",
      "  Found 0 articles, extracting content...\n",
      "Saved 7 articles for category 'finance'\n",
      "\n",
      "Crawling websites for category: sports\n",
      "  Getting links from https://www.espn.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Getting links from https://sports.yahoo.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: Yahoo Sports...\n",
      "  Extracted: Yahoo Sports...\n",
      "  Extracted: Yahoo Sports...\n",
      "  Extracted: Yahoo Sports...\n",
      "  Extracted: Will be right back......\n",
      "  Extracted: Yahoo Sports...\n",
      "  Extracted: Yahoo Sports...\n",
      "  Extracted: Yahoo Sports...\n",
      "  Extracted: Yahoo Sports...\n",
      "  Extracted: Yahoo Sports...\n",
      "  Getting links from https://www.cbssports.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: Winthrop vs. High Point prediction, odds: 2025 Big...\n",
      "  Extracted: Dan Hurley in '60 Minutes' interview: UConn coach ...\n",
      "  Extracted: 2025 March Madness, conference tournament brackets...\n",
      "  Extracted: LeBron James injury: How the Lakers can survive th...\n",
      "  Extracted: Drake vs. Bradley odds, how to watch, free picks: ...\n",
      "  Extracted: Steelers legend Hines Ward says this college QB re...\n",
      "  Extracted: Nuggets vs. Thunder odds, line, prediction, start ...\n",
      "  Extracted: Real Madrid vs. Rayo Vallecano: Odds, live stream,...\n",
      "  Extracted: Warriors' Stephen Curry surpasses 25K points, and ...\n",
      "  Extracted: Fantasy Baseball Today: Spring Training buzz, Shan...\n",
      "Saved 20 articles for category 'sports'\n",
      "\n",
      "Crawling websites for category: entertainment\n",
      "  Getting links from https://variety.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: Trump Says He Will Issue a ‘Complete Pardon’ of Pe...\n",
      "  Extracted: Dave Bautista on Joining Milla Jovovich and Paul W...\n",
      "  Extracted: Cobel Returns! ‘Severance’ Star Patricia Arquette ...\n",
      "  Extracted: Adrien Brody Wins Oscar, Throws Out His Gum and Te...\n",
      "  Extracted: Emmy Rule Changes Revealed by Television Academy: ...\n",
      "  Extracted: Lady Gaga Goes Full ‘Killah’ in Kinetic ‘SNL’ Perf...\n",
      "  Extracted: ‘No Other Land’ Directors Use Oscar Speech to Call...\n",
      "  Extracted: Cher Performs as Elvis, Alicia Keys Honors Roberta...\n",
      "  Extracted: Adam Lambert on Playing the Emcee in Broadway’s ‘C...\n",
      "  Extracted: ‘Anora’ Won Best Picture: Here’s How to Watch the ...\n",
      "  Getting links from https://www.hollywoodreporter.com/\n",
      "  Found 6 articles, extracting content...\n",
      "  Extracted: News...\n",
      "  Extracted: Latest Local News...\n",
      "  Extracted: Latest TV Features...\n",
      "  Extracted: Latest Politics News...\n",
      "  Extracted: Latest Music News...\n",
      "  Extracted: Latest General News...\n",
      "  Getting links from https://deadline.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: ‘1923’s Julia Schlaepfer On Her Harrowing Scenes A...\n",
      "  Extracted: Sad Weekend For Lofty Priced, Original Sci-Fi Fare...\n",
      "  Extracted: Gabriel Macht Returns As Harvey Specter In ‘Suits ...\n",
      "  Extracted: ‘The Accountant 2’ Review: Ben Affleck Has Brother...\n",
      "  Extracted: Wildfires In The Hamptons Now Contained, But Weath...\n",
      "  Extracted: John Goodman Injured During Filming Of Warner Bros...\n",
      "  Extracted: Did Netflix’s Algorithm & Scheduling Doom ‘The Rec...\n",
      "  Extracted: Peter Bart: As Amazon Decides How To Reinvent Jame...\n",
      "  Extracted: ‘The Studio’ Trailer: Seth Rogen Is Desperate For ...\n",
      "  Extracted: SXSW 2025: All Of Deadline’s Movie Reviews...\n",
      "Saved 26 articles for category 'entertainment'\n",
      "\n",
      "Crawling websites for category: science\n",
      "  Getting links from https://www.scientificamerican.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: Neuroscientists Should Set a High Bar for Evidence...\n",
      "  Extracted: Where Are the Universe’s Missing Planets?...\n",
      "  Extracted: COVID Pandemic Fatigue Has Left the U.S. Vulnerabl...\n",
      "  Extracted: Scientific American Magazine...\n",
      "  Extracted: How Anime Fans Stumbled upon a Mathematical Proof...\n",
      "  Extracted: What Is Chloroprene, the Cancer-Causing Chemical a...\n",
      "  Extracted: Daylight Saving Time and Early School Start Times ...\n",
      "  Extracted: This Backyard Bird Has a Lot to Teach Us about Sex...\n",
      "  Extracted: Company Seeking to Resurrect the Woolly Mammoth Cr...\n",
      "  Extracted: Inside the AI Competition That Decoded an Ancient ...\n",
      "  Getting links from https://www.livescience.com/\n",
      "  Found 0 articles, extracting content...\n",
      "  Getting links from https://www.nature.com/news\n",
      "  Found 0 articles, extracting content...\n",
      "Saved 10 articles for category 'science'\n",
      "\n",
      "Crawling websites for category: travel\n",
      "  Getting links from https://www.travelandleisure.com/\n",
      "  Found 0 articles, extracting content...\n",
      "  Getting links from https://www.lonelyplanet.com/\n",
      "  Found 0 articles, extracting content...\n",
      "  Getting links from https://www.nationalgeographic.com/travel/\n",
      "  Found 10 articles, extracting content...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Extracted: China’s other great wall is impressive, too—and st...\n",
      "  Extracted: 10 family-friendly things to do in Texas...\n",
      "  Extracted: 10 family-friendly hotels in Texas, from El Paso t...\n",
      "  Extracted: A practical guide to travelling in southern Mexico...\n",
      "  Extracted: The unexpected wine country you need to visit: New...\n",
      "  Extracted: It's the 100th anniversary of The Great Gatsby and...\n",
      "  Extracted: Meet the female rappers carving out a home in Nash...\n",
      "  Extracted: National Geographic Masthead...\n",
      "  Extracted: Where to try the 6 traditional dishes served on ‘N...\n",
      "  Extracted: Where to travel in April...\n",
      "Saved 10 articles for category 'travel'\n",
      "\n",
      "Crawling websites for category: food\n",
      "  Getting links from https://www.allrecipes.com/\n",
      "  Found 3 articles, extracting content...\n",
      "  Extracted: Secrets to the Perfect St. Paddy's Day Corned Beef...\n",
      "  Extracted: Tips for Submitting Your Recipe to Allrecipes...\n",
      "  Extracted: How To Make Irish Soda Bread...\n",
      "  Getting links from https://www.epicurious.com/\n",
      "  Found 0 articles, extracting content...\n",
      "  Getting links from https://www.bonappetit.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: Slow-Roasted Salmon and More Recipes We Made This ...\n",
      "  Extracted: Should Kids Be Allowed in Fine Dining Restaurants?...\n",
      "  Extracted: 8 Coolest Wine Decanters to Show Off That Great Bo...\n",
      "  Extracted: The Best Rice Cookers for Effortless Fluffy Rice E...\n",
      "  Extracted: Accessibility Help...\n",
      "  Extracted: The Best Kitchen Trash Cans for Keeping Your Kitch...\n",
      "  Extracted: 10 Australian Wines We’ll Be Sipping All Year...\n",
      "  Extracted: How to Safely Use Expired Milk...\n",
      "  Extracted: I Need High-Protein, Family-Friendly Recipes...\n",
      "  Extracted: I Tried a Dozen Dish Drying Racks—And This One Is ...\n",
      "Saved 13 articles for category 'food'\n",
      "\n",
      "Crawling websites for category: education\n",
      "  Getting links from https://www.edutopia.org/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: 4 Classroom Design Tactics to Motivate Students...\n",
      "  Extracted: 3 Ways to Bring Makerspace Principles Into STEM Cl...\n",
      "  Extracted: Assessing the Child-Centeredness of Your Teaching ...\n",
      "  Extracted: What a 30-Day Break From AI Taught Me About My Tea...\n",
      "  Extracted: How to Select Effective PD Facilitators...\n",
      "  Extracted: Assessing the Child-Centeredness of Your Teaching ...\n",
      "  Extracted: 4 Classroom Design Tactics to Motivate Students...\n",
      "  Extracted: Maintaining Students’ Focus in the Spring...\n",
      "  Extracted: Question: Is AI Harmful to Education?...\n",
      "  Extracted: How to Support Floating Teachers...\n",
      "  Getting links from https://www.edweek.org/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: Teachers, Try This: Use Dance to Boost Engagement ...\n",
      "  Getting links from https://www.insidehighered.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: Public Largely Disapproves of Student Protests...\n",
      "  Extracted: Colleges Restrict Graduate Student Admissions Afte...\n",
      "  Extracted: Creating Space for Disagreement on Campus...\n",
      "Saved 14 articles for category 'education'\n",
      "\n",
      "Crawling websites for category: environment\n",
      "  Getting links from https://www.nationalgeographic.com/environment/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: Canada's beloved outdoor ice rinks are melting awa...\n",
      "  Extracted: Sound waves and sea creatures...\n",
      "  Extracted: The 'least spectacular' of the Great Lakes is a de...\n",
      "  Extracted: What’s behind the strange rash of ’dinosaur’ sight...\n",
      "  Extracted: The world's largest iceberg is on a collision cour...\n",
      "  Extracted: National Geographic Masthead...\n",
      "  Extracted: Wildfires are making their way east—where they cou...\n",
      "  Extracted: Marine engineers: Five species that shape underwat...\n",
      "  Extracted: What drew these 1,300 perfect circles on the sea f...\n",
      "  Extracted: Are these the last days of Brazil's realm of hidde...\n",
      "  Getting links from https://www.nature.org/\n",
      "  Found 0 articles, extracting content...\n",
      "  Getting links from https://www.ecowatch.com/\n",
      "  Found 0 articles, extracting content...\n",
      "Saved 10 articles for category 'environment'\n",
      "\n",
      "Crawling websites for category: politics\n",
      "  Getting links from https://www.politico.com/\n",
      "  Found 0 articles, extracting content...\n",
      "  Getting links from https://thehill.com/\n",
      "  Found 0 articles, extracting content...\n",
      "  Getting links from https://www.fivethirtyeight.com/\n",
      "  Found 0 articles, extracting content...\n",
      "Saved 0 articles for category 'politics'\n",
      "\n",
      "Crawling websites for category: fashion\n",
      "  Getting links from https://www.vogue.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: How to Watch This Year’s Oscar-Winning Films...\n",
      "  Extracted: And This Year’s Unlikely Awards-Season Darling Is…...\n",
      "  Extracted: Need a Present for a New Parent? A Month-by-Month ...\n",
      "  Extracted: The White Lotus Stars Check Into Fashion Month...\n",
      "  Extracted: 7 Movies About the Sex Work Industry to Watch Afte...\n",
      "  Extracted: Meghan Markle Models Power Lunch Style While Out W...\n",
      "  Extracted: From the Archives: A “Complete Unknown” Haider Ack...\n",
      "  Extracted: 7 Chefs on the Women Who Shaped Their Culinary Voi...\n",
      "  Extracted: Hermès’s Subtle Smoky Eye Is the Easiest New Seaso...\n",
      "  Extracted: Rihanna Dresses Cozy and Classic to Solo Dine at H...\n",
      "  Getting links from https://www.elle.com/\n",
      "  Found 1 articles, extracting content...\n",
      "  Extracted: Here’s Your Complete 2025 Horoscope...\n",
      "  Getting links from https://www.harpersbazaar.com/\n",
      "  Found 0 articles, extracting content...\n",
      "Saved 11 articles for category 'fashion'\n",
      "\n",
      "Crawling websites for category: art\n",
      "  Getting links from https://www.artnews.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: Juan Hamilton, Protégé and Beneficiary of Georgia ...\n",
      "  Extracted: Archaeologists Discover Cache of Ancient Gold Jewe...\n",
      "  Extracted: ACLU Sues NEA over ‘Gender Ideology’ Funding Polic...\n",
      "  Extracted: Texas Lawmakers Take Aim at Pro-Palestine Student ...\n",
      "  Extracted: Ricardo Scofidio, Architect Who Transformed the Am...\n",
      "  Extracted: Bayeux Tapestry Fragment Found in Northern German ...\n",
      "  Extracted: Art Institute of Chicago Returns Stolen Buddha to ...\n",
      "  Extracted: The 100 Best Artworks of the 21st Century...\n",
      "  Extracted: Nvidia CEO’s Foundation Rescues Ailing California ...\n",
      "  Getting links from https://www.artforum.com/\n",
      "  Found 6 articles, extracting content...\n",
      "  Extracted: Sally Mann Photos Seized from Texas Museum Followi...\n",
      "  Extracted: ACLU Sues NEA Over Adherence to Trump Anti-Trans M...\n",
      "  Extracted: Nora Razian and Sabih Ahmed to Curate Third Diriya...\n",
      "  Extracted: Liu Jiakun Awarded 2025 Pritzker Prize...\n",
      "  Extracted: Máret Ánne Sara Wins Tate Modern’s 2025 Turbine Ha...\n",
      "  Getting links from https://news.artnet.com/\n",
      "  Found 0 articles, extracting content...\n",
      "Saved 14 articles for category 'art'\n",
      "\n",
      "Crawling websites for category: automotive\n",
      "  Getting links from https://www.caranddriver.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: Tariffs, Even If Delayed, Could Get Big Reactions ...\n",
      "  Extracted: 2025 Chevy Blazer vs. Honda Passport vs. Nissan Mu...\n",
      "  Extracted: Best Cars for Uber Black: Window Shop with Car and...\n",
      "  Extracted: 10Best Trucks for 2025: All the Winning SUVs, Truc...\n",
      "  Extracted: 2025 Nissan Z Isn't More Expensive and Adds an Ico...\n",
      "  Extracted: 1980 BMW 733i Tested: Roll Out the Superlatives...\n",
      "  Extracted: News...\n",
      "  Extracted: Nissan GT-R Order Books Close in Japan, Is This Go...\n",
      "  Extracted: 1980 Subaru 1600 4WD Test: Terms of Endearment...\n",
      "  Extracted: Future Electric Vehicles: The EVs You'll Soon Be A...\n",
      "  Getting links from https://www.motortrend.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: 2026 Cadillac Escalade IQL First Look: That's EV f...\n",
      "  Extracted: Kia PV5 Electric Van First Look: More Details on a...\n",
      "  Extracted: Is Ford Developing a 4-Door Mustang \"Mach 4\" Sedan...\n",
      "  Extracted: Kia Concept EV2 First Look: Shrunken EV With Even ...\n",
      "  Extracted: Can We Please Get EV Motors Out of the Actual Car?...\n",
      "  Extracted: The World's Smallest V-8-Powered Supercar Is Final...\n",
      "  Extracted: Hyundai Motor Co. President Jose Muñoz Is the 2025...\n",
      "  Extracted: Tesla Plans To Give \"Some Love\" to Aging Model S a...\n",
      "  Extracted: 2026 Kia EV4 First Look: Smaller Size,  Smaller Pr...\n",
      "  Extracted: From Dirt to Dealerships? The 2025 Chevrolet Silve...\n",
      "  Getting links from https://www.autocar.co.uk/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 0 articles, extracting content...\n",
      "Saved 20 articles for category 'automotive'\n",
      "\n",
      "Crawling websites for category: business\n",
      "  Getting links from https://www.forbes.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: Malaysian Tycoon Lim Han Weng’s HI Mobility Adding...\n",
      "  Extracted: Forbes Editorial Values And Standards...\n",
      "  Extracted: Trump Threatens New Tariffs On Canada As Soon As T...\n",
      "  Extracted: Stocks Suffer Worst Week In 6 Months—Despite Frida...\n",
      "  Extracted: Elon Musk Dubiously Blames Billionaires George Sor...\n",
      "  Extracted: Here’s Where Trump’s Government Layoffs Are Target...\n",
      "  Extracted: Gene Hackman Died Of Heart Disease—And Wife Killed...\n",
      "  Extracted: Hong Kong’s 50 Richest 2025: Stock Market Rally Li...\n",
      "  Extracted: Trump Won’t Deny There Could Be A Recession—Warns ...\n",
      "  Extracted: CDC Plans Large Study On Long-Debunked Connection ...\n",
      "  Getting links from https://www.entrepreneur.com/\n",
      "  Found 2 articles, extracting content...\n",
      "  Extracted: New Tech That Will Impress Your Coworkers in 2025\n",
      "...\n",
      "  Getting links from https://hbr.org/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: When Your Colleague Is Jealous of Your Success...\n",
      "  Extracted: The Evolution of Luxury Brand Porsche...\n",
      "  Extracted: Is AI the Right Tool to Solve That Problem?...\n",
      "  Extracted: 3 Ways Multinationals Can Invest in China—Without ...\n",
      "  Extracted: Research: To Retain Employees, Promote Them Before...\n",
      "  Extracted: Why Marketers Are Spending Less on Social Media...\n",
      "  Extracted: Leaders Shouldn’t Try to Do It All...\n",
      "  Extracted: The Strategic Genius of Taylor Swift...\n",
      "  Extracted: How to Get Better at Delegating...\n",
      "  Extracted: Research: When Prototypes Don’t Yield Useful Insig...\n",
      "Saved 21 articles for category 'business'\n",
      "\n",
      "Crawling websites for category: real_estate\n",
      "  Getting links from https://www.realtor.com/news/\n",
      "  Found 10 articles, extracting content...\n",
      "  Getting links from https://www.zillow.com/blog/\n",
      "  Found 0 articles, extracting content...\n",
      "  Getting links from https://www.redfin.com/news/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: Rental Market News...\n",
      "  Extracted article\n",
      "  Extracted: Contact Us...\n",
      "  Extracted: Data Center...\n",
      "  Extracted: From Our Economists...\n",
      "Saved 5 articles for category 'real_estate'\n",
      "\n",
      "Crawling websites for category: gaming\n",
      "  Getting links from https://www.ign.com/\n",
      "Error fetching links from https://www.ign.com/: HTTPSConnectionPool(host='www.ign.com', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1006)')))\n",
      "  Found 0 articles, extracting content...\n",
      "  Getting links from https://www.gamespot.com/\n",
      "Error fetching links from https://www.gamespot.com/: HTTPSConnectionPool(host='www.gamespot.com', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1006)')))\n",
      "  Found 0 articles, extracting content...\n",
      "  Getting links from https://kotaku.com/\n",
      "Error fetching links from https://kotaku.com/: HTTPSConnectionPool(host='kotaku.com', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1006)')))\n",
      "  Found 0 articles, extracting content...\n",
      "Saved 0 articles for category 'gaming'\n",
      "\n",
      "Crawling websites for category: pets\n",
      "  Getting links from https://www.akc.org/\n",
      "  Found 0 articles, extracting content...\n",
      "  Getting links from https://www.petmd.com/\n",
      "  Found 1 articles, extracting content...\n",
      "  Extracted: Alerts & Recalls...\n",
      "  Getting links from https://www.thesprucepets.com/\n",
      "  Found 0 articles, extracting content...\n",
      "Saved 1 articles for category 'pets'\n",
      "\n",
      "Crawling websites for category: history\n",
      "  Getting links from https://www.history.com/\n",
      "  Found 6 articles, extracting content...\n",
      "  Extracted: How FDR’s ‘Fireside Chats’ Helped Calm a Nation in...\n",
      "  Extracted: 8 Ways ‘The Great Gatsby’ Captured the Roaring Twe...\n",
      "  Extracted: How Selma’s ‘Bloody Sunday’ Became a Turning Point...\n",
      "  Extracted: 8 Things You May Not Know About Daylight Saving Ti...\n",
      "  Extracted: When Harriet Tubman Led a Brazen Civil War Raid...\n",
      "  Extracted: Why Do We Have Daylight Saving Time?...\n",
      "  Getting links from https://www.historyextra.com/\n",
      "  Found 0 articles, extracting content...\n",
      "  Getting links from https://www.ancient-origins.net/\n",
      "  Found 0 articles, extracting content...\n",
      "Saved 6 articles for category 'history'\n",
      "\n",
      "Crawling websites for category: psychology\n",
      "  Getting links from https://www.psychologytoday.com/\n",
      "  Found 10 articles, extracting content...\n",
      "  Extracted: The Executive-Athlete Mindset: Achieving Peak Perf...\n",
      "  Extracted: Is \"Paying Attention\" Overrated for Kids?...\n",
      "  Extracted: The Power of Soulful Sisterhood...\n",
      "  Extracted: Creating 2 Pink Lines...\n",
      "  Extracted: Happy Together...\n",
      "  Extracted: Black Belt Brain...\n",
      "  Extracted: Beyond Mental Health...\n",
      "  Extracted: Two Types of Financial Gurus, and Why You Should I...\n",
      "  Extracted: The Unique Challenges Faced by Women With ADHD...\n",
      "  Extracted: Brain Curiosities...\n",
      "  Getting links from https://www.apa.org/\n",
      "  Found 0 articles, extracting content...\n",
      "  Getting links from https://www.verywellmind.com/\n",
      "  Found 0 articles, extracting content...\n",
      "Saved 10 articles for category 'psychology'\n"
     ]
    }
   ],
   "source": [
    "all_data = {}\n",
    "\n",
    "for category, websites in tqdm(categories.items(), desc=\"Processing categories\"):\n",
    "    print(f\"\\nCrawling websites for category: {category}\")\n",
    "    category_data = []\n",
    "    \n",
    "    for website in websites:\n",
    "        print(f\"  Getting links from {website}\")\n",
    "        article_links = get_article_links(website)\n",
    "        \n",
    "        print(f\"  Found {len(article_links)} articles, extracting content...\")\n",
    "        for link in article_links:\n",
    "            # Add a random delay to be respectful to the websites\n",
    "            time.sleep(random.uniform(1, 3))\n",
    "            \n",
    "            article_data = extract_article_content(link)\n",
    "            if article_data['content']:  # Only add if we got some content\n",
    "                category_data.append(article_data)\n",
    "                print(f\"  Extracted: {article_data['title'][:50]}...\" if article_data['title'] else \"  Extracted article\")\n",
    "    \n",
    "    all_data[category] = category_data\n",
    "    \n",
    "    # Save raw data to file\n",
    "    raw_file_path = os.path.join('raw_data', f\"{category}_raw.txt\")\n",
    "    with open(raw_file_path, 'w', encoding='utf-8') as f:\n",
    "        for article in category_data:\n",
    "            f.write(f\"URL: {article['url']}\\n\")\n",
    "            f.write(f\"TITLE: {article['title']}\\n\")\n",
    "            f.write(f\"DATE: {article['date']}\\n\")\n",
    "            f.write(f\"CONTENT:\\n{article['content']}\\n\")\n",
    "            f.write(\"-\" * 80 + \"\\n\")\n",
    "    \n",
    "    print(f\"Saved {len(category_data)} articles for category '{category}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585080e5",
   "metadata": {},
   "source": [
    "Clean the text using NLP preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa7a3f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1786e1e1f74ee086045dc5bf1ef203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaning text data:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned text for category 'technology'\n",
      "Saved cleaned text for category 'health'\n",
      "Saved cleaned text for category 'finance'\n",
      "Saved cleaned text for category 'sports'\n",
      "Saved cleaned text for category 'entertainment'\n",
      "Saved cleaned text for category 'science'\n",
      "Saved cleaned text for category 'travel'\n",
      "Saved cleaned text for category 'food'\n",
      "Saved cleaned text for category 'education'\n",
      "Saved cleaned text for category 'environment'\n",
      "Saved cleaned text for category 'politics'\n",
      "Saved cleaned text for category 'fashion'\n",
      "Saved cleaned text for category 'art'\n",
      "Saved cleaned text for category 'automotive'\n",
      "Saved cleaned text for category 'business'\n",
      "Saved cleaned text for category 'real_estate'\n",
      "Saved cleaned text for category 'gaming'\n",
      "Saved cleaned text for category 'pets'\n",
      "Saved cleaned text for category 'history'\n",
      "Saved cleaned text for category 'psychology'\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Apply NLP preprocessing to clean the text\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    \n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Rejoin tokens\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Process and save cleaned data for each category\n",
    "for category, articles in tqdm(all_data.items(), desc=\"Cleaning text data\"):\n",
    "    cleaned_texts = []\n",
    "    \n",
    "    for article in articles:\n",
    "        cleaned_title = clean_text(article['title'])\n",
    "        cleaned_content = clean_text(article['content'])\n",
    "        \n",
    "        cleaned_texts.append(f\"{cleaned_title} {cleaned_content}\")\n",
    "    \n",
    "    # Save cleaned data to file\n",
    "    cleaned_file_path = os.path.join('cleaned_data', f\"{category}_cleaned.txt\")\n",
    "    with open(cleaned_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(cleaned_texts))\n",
    "    \n",
    "    print(f\"Saved cleaned text for category '{category}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7464dea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple feature extraction function\n",
    "def extract_features(text, common_words_per_category):\n",
    "    \"\"\"Extract features based on the presence of category-specific words\"\"\"\n",
    "    features = {}\n",
    "    words = set(text.split())\n",
    "    \n",
    "    for category, common_words in common_words_per_category.items():\n",
    "        # Count how many common words from each category appear in the text\n",
    "        category_score = sum(1 for word in common_words if word in words)\n",
    "        features[f\"{category}_score\"] = category_score\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c845f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most common words per category (simplified TF-IDF approach)\n",
    "common_words_per_category = {}\n",
    "\n",
    "for category in categories.keys():\n",
    "    cleaned_file_path = os.path.join('cleaned_data', f\"{category}_cleaned.txt\")\n",
    "    try:\n",
    "        with open(cleaned_file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        # Get word frequencies\n",
    "        words = text.split()\n",
    "        word_freq = {}\n",
    "        for word in words:\n",
    "            if len(word) > 3:  # Only consider words longer than 3 characters\n",
    "                word_freq[word] = word_freq.get(word, 0) + 1\n",
    "        \n",
    "        # Get top 20 words\n",
    "        top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "        common_words_per_category[category] = [word for word, _ in top_words]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {category}: {e}\")\n",
    "        common_words_per_category[category] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df0fd6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sample data for classifier demonstration\n",
    "samples = []\n",
    "\n",
    "for category in categories.keys():\n",
    "    cleaned_file_path = os.path.join('cleaned_data', f\"{category}_cleaned.txt\")\n",
    "    try:\n",
    "        with open(cleaned_file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Take first 2 samples from each category\n",
    "        for i, line in enumerate(lines[:2]):\n",
    "            samples.append({\n",
    "                'text': line,\n",
    "                'actual_category': category\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting samples for {category}: {e}\")\n",
    "\n",
    "# Classify samples\n",
    "for sample in samples:\n",
    "    features = extract_features(sample['text'], common_words_per_category)\n",
    "    \n",
    "    # Find category with highest score\n",
    "    predicted_category = max(features.items(), key=lambda x: x[1])[0].split('_')[0]\n",
    "    \n",
    "    sample['predicted_category'] = predicted_category\n",
    "    sample['features'] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ceef215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple classifier accuracy: 0.66 (23/35)\n",
      "\n",
      "Sample Classifications:\n",
      "Sample 1:\n",
      "  Actual category: technology\n",
      "  Predicted category: technology\n",
      "  Text snippet: apples smart home hub reportedly delayed siri challenges latest ai amazon apps biotech health climat...\n",
      "\n",
      "Sample 2:\n",
      "  Actual category: technology\n",
      "  Predicted category: technology\n",
      "  Text snippet: judge allows authors ai copyright lawsuit meta move forward latest ai amazon apps biotech health cli...\n",
      "\n",
      "Sample 3:\n",
      "  Actual category: health\n",
      "  Predicted category: health\n",
      "  Text snippet: fda approves new treatment stroke march fda approved first newâ clotbustingâ drug nearly years offer...\n",
      "\n",
      "Sample 4:\n",
      "  Actual category: health\n",
      "  Predicted category: health\n",
      "  Text snippet: common vaginal issue really std study march â men whose female sex partners get itchy vaginal infect...\n",
      "\n",
      "Sample 5:\n",
      "  Actual category: finance\n",
      "  Predicted category: finance\n",
      "  Text snippet: evtols flying cars finally becoming reality video inventors fixated idea flying cars nearly long roa...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "correct = sum(1 for sample in samples if sample['actual_category'] == sample['predicted_category'])\n",
    "accuracy = correct / len(samples) if samples else 0\n",
    "\n",
    "print(f\"Simple classifier accuracy: {accuracy:.2f} ({correct}/{len(samples)})\")\n",
    "\n",
    "# Display sample classifications\n",
    "print(\"\\nSample Classifications:\")\n",
    "for i, sample in enumerate(samples[:5]):  # Show first 5 samples\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"  Actual category: {sample['actual_category']}\")\n",
    "    print(f\"  Predicted category: {sample['predicted_category']}\")\n",
    "    print(f\"  Text snippet: {sample['text'][:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f926677e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Summary:\n",
      "Name: MultiDomain-TextCorpus\n",
      "Description: A comprehensive text dataset covering 20 different domains with articles collected from 3 websites per domain.\n",
      "Total categories: 20\n",
      "Total articles: 222\n",
      "Average content length: 6325.24 characters\n",
      "\n",
      "Articles per category:\n",
      "  technology: 20\n",
      "  health: 4\n",
      "  finance: 7\n",
      "  sports: 20\n",
      "  entertainment: 26\n",
      "  science: 10\n",
      "  travel: 10\n",
      "  food: 13\n",
      "  education: 14\n",
      "  environment: 10\n",
      "  politics: 0\n",
      "  fashion: 11\n",
      "  art: 14\n",
      "  automotive: 20\n",
      "  business: 21\n",
      "  real_estate: 5\n",
      "  gaming: 0\n",
      "  pets: 1\n",
      "  history: 6\n",
      "  psychology: 10\n"
     ]
    }
   ],
   "source": [
    "# Save the dataset information\n",
    "dataset_info = {\n",
    "    'name': 'MultiDomain-TextCorpus',\n",
    "    'description': 'A comprehensive text dataset covering 20 different domains with articles collected from 3 websites per domain.',\n",
    "    'categories': list(categories.keys()),\n",
    "    'total_articles': sum(len(articles) for articles in all_data.values()),\n",
    "    'articles_per_category': {category: len(articles) for category, articles in all_data.items()},\n",
    "    'average_content_length': sum(len(article['content']) for articles in all_data.values() for article in articles) / \n",
    "                              sum(len(articles) for articles in all_data.values() if articles),\n",
    "}\n",
    "\n",
    "print(\"\\nDataset Summary:\")\n",
    "print(f\"Name: {dataset_info['name']}\")\n",
    "print(f\"Description: {dataset_info['description']}\")\n",
    "print(f\"Total categories: {len(dataset_info['categories'])}\")\n",
    "print(f\"Total articles: {dataset_info['total_articles']}\")\n",
    "print(f\"Average content length: {dataset_info['average_content_length']:.2f} characters\")\n",
    "print(\"\\nArticles per category:\")\n",
    "for category, count in dataset_info['articles_per_category'].items():\n",
    "    print(f\"  {category}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb78eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset statistics saved to 'dataset_stats.csv'\n"
     ]
    }
   ],
   "source": [
    "# Export dataset information to CSV\n",
    "dataset_stats = pd.DataFrame([{\n",
    "    'Category': category,\n",
    "    'Articles': count,\n",
    "    'Websites': ', '.join(categories[category])\n",
    "} for category, count in dataset_info['articles_per_category'].items()])\n",
    "\n",
    "dataset_stats.to_csv('dataset_stats.csv', index=False)\n",
    "print(\"\\nDataset statistics saved to 'dataset_stats.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7265d95",
   "metadata": {},
   "source": [
    "Challenge: Demonstrate a use case - Create a simple document classifier\n",
    "MultiDomain-TextCorpus Use Case: Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b5ee87",
   "metadata": {},
   "source": [
    "\n",
    "Dataset Name: WebText20: A Multi-Domain Text Dataset\n",
    "\n",
    "Use Case: This dataset can be used for topic modeling, text classification, NLP-based recommendation systems, and AI-driven content summarization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
